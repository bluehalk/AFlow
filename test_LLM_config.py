#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• config2.yaml é…ç½®å’ŒAPIè¿æ¥
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from scripts.async_llm import LLMsConfig, AsyncLLM
from scripts.logs import logger

async def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    print("ğŸ” å¼€å§‹æµ‹è¯•APIé…ç½®...")
    
    try:
        # 1. æµ‹è¯•é…ç½®åŠ è½½
        print("\n1ï¸âƒ£ æµ‹è¯•é…ç½®åŠ è½½...")
        config = LLMsConfig.default()
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {config.get_all_names()}")
        
        # 2. æµ‹è¯•æ¨¡å‹é…ç½®è·å–
        print("\n2ï¸âƒ£ æµ‹è¯•æ¨¡å‹é…ç½®è·å–...")
        opt_config = config.get('llama3-70b-8192')
        exec_config = config.get('llama3-70b-8192')
        
        print(f"ğŸ”§ ä¼˜åŒ–æ¨¡å‹é…ç½®:")
        print(f"   - base_url: {opt_config.base_url}")
        print(f"   - model: {opt_config.model}")
        print(f"   - temperature: {opt_config.temperature}")
        print(f"   - api_key: {opt_config.key[:10]}..." if opt_config.key else "   - api_key: None")
        
        print(f"âš¡ æ‰§è¡Œæ¨¡å‹é…ç½®:")
        print(f"   - base_url: {exec_config.base_url}")
        print(f"   - model: {exec_config.model}")
        print(f"   - temperature: {exec_config.temperature}")
        print(f"   - api_key: {exec_config.key[:10]}..." if exec_config.key else "   - api_key: None")
        
        # 3. æµ‹è¯•APIè¿æ¥
        print("\n3ï¸âƒ£ æµ‹è¯•APIè¿æ¥...")
        
        # æµ‹è¯•æ‰§è¡Œæ¨¡å‹
        print("ğŸ” æµ‹è¯•æ‰§è¡Œæ¨¡å‹è¿æ¥...")
        exec_llm = AsyncLLM('llama3-70b-8192')
        
        test_prompt = "è¯·å›ç­”ï¼š1 + 1 = ?"
        print(f"ğŸ“ å‘é€æµ‹è¯•è¯·æ±‚: {test_prompt}")
        
        try:
            response = await exec_llm(test_prompt)
            print(f"âœ… æ‰§è¡Œæ¨¡å‹å“åº”æˆåŠŸ!")
            print(f"ğŸ“„ å“åº”å†…å®¹: {response}")
            # è·å–æˆæœ¬ä¿¡æ¯
            usage_summary = exec_llm.get_usage_summary()
            cost = usage_summary['total_cost']
            print(f"ğŸ’° æˆæœ¬: ${cost:.6f}")
        except Exception as e:
            print(f"âŒ æ‰§è¡Œæ¨¡å‹è¿æ¥å¤±è´¥: {e}")
            return False
        
        # æµ‹è¯•ä¼˜åŒ–æ¨¡å‹
        print("\nğŸ” æµ‹è¯•ä¼˜åŒ–æ¨¡å‹è¿æ¥...")
        opt_llm = AsyncLLM('llama3-70b-8192')
        
        test_prompt = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
        print(f"ğŸ“ å‘é€æµ‹è¯•è¯·æ±‚: {test_prompt}")
        
        try:
            response = await opt_llm(test_prompt)
            print(f"âœ… ä¼˜åŒ–æ¨¡å‹å“åº”æˆåŠŸ!")
            print(f"ğŸ“„ å“åº”å†…å®¹: {response}")
            # è·å–æˆæœ¬ä¿¡æ¯
            usage_summary = opt_llm.get_usage_summary()
            cost = usage_summary['total_cost']
            print(f"ğŸ’° æˆæœ¬: ${cost:.6f}")
        except Exception as e:
            print(f"âŒ ä¼˜åŒ–æ¨¡å‹è¿æ¥å¤±è´¥: {e}")
            return False
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False

async def test_groq_specific():
    """æµ‹è¯•Groq APIç‰¹å®šé…ç½®"""
    print("\nğŸ”§ æµ‹è¯•Groq APIç‰¹å®šé…ç½®...")
    
    try:
        # æµ‹è¯•ä¸åŒçš„æ¨¡å‹åç§°
        test_models = [
            "llama3-70b-8192",
        ]
        
        config = LLMsConfig.default()
        
        for model_name in test_models:
            print(f"\nğŸ” æµ‹è¯•æ¨¡å‹: {model_name}")
            try:
                llm_config = config.get(model_name)
                print(f"   âœ… é…ç½®è·å–æˆåŠŸ")
                print(f"   ğŸ“ base_url: {llm_config.base_url}")
                print(f"   ğŸ¤– model: {llm_config.model}")
                
                # æµ‹è¯•è¿æ¥
                llm = AsyncLLM(model_name)
                response = await llm("Hello, test message")
                print(f"   âœ… APIè¿æ¥æˆåŠŸ")
                # è·å–æˆæœ¬ä¿¡æ¯
                usage_summary = llm.get_usage_summary()
                cost = usage_summary['total_cost']
                print(f"   ğŸ’° æˆæœ¬: ${cost:.6f}")
                
            except Exception as e:
                print(f"   âŒ å¤±è´¥: {e}")
                
    except Exception as e:
        print(f"âŒ Groqæµ‹è¯•å¤±è´¥: {e}")

def check_config_file():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶å†…å®¹"""
    print("ğŸ“ æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    
    config_path = "config/config2.yaml"
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    
    with open(config_path, 'r', encoding='utf-8') as f:
        content = f.read()
        print(f"âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {config_path}")
        print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
        
        # æ£€æŸ¥å…³é”®é…ç½®
        if "llama3-70b-8192" in content:
            print("âœ… æ‰¾åˆ°æ‰§è¡Œæ¨¡å‹é…ç½®")
        else:
            print("âŒ æœªæ‰¾åˆ°æ‰§è¡Œæ¨¡å‹é…ç½®")
            
        if "https://api.groq.com/openai/v1" in content:
            print("âœ… æ‰¾åˆ°æ­£ç¡®çš„Groq API URL")
        else:
            print("âŒ æœªæ‰¾åˆ°æ­£ç¡®çš„Groq API URL")
            
        if "gsk_" in content:
            print("âœ… æ‰¾åˆ°APIå¯†é’¥é…ç½®")
        else:
            print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥é…ç½®")
    
    return True

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹AFlowé…ç½®æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not check_config_file():
        return
    
    # æµ‹è¯•APIè¿æ¥
    success = await test_api_connection()
    
    if success:
        print("\n" + "=" * 50)
        print("ğŸ‰ é…ç½®æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼å¯ä»¥è¿è¡ŒAFlowå®éªŒäº†")
        print("\nğŸ’¡ è¿è¡Œå‘½ä»¤:")
        print("python run.py --dataset GSM8K \\")
        print("    --opt_model_name 'llama3-70b-8192' \\")
        print("    --exec_model_name 'llama3-70b-8192' \\")
        print("    --sample 2 --max_rounds 2 --validation_rounds 1")
    else:
        print("\n" + "=" * 50)
        print("âŒ é…ç½®æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹é—®é¢˜:")
        print("1. APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        print("2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("3. Groq APIæœåŠ¡æ˜¯å¦å¯ç”¨")
        print("4. æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
        
        # é¢å¤–æµ‹è¯•
        await test_groq_specific()

if __name__ == "__main__":
    asyncio.run(main()) 