#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GSM8Kå°è§„æ¨¡æµ‹è¯•è„šæœ¬ - åªç”¨5ä¸ªæ ·æœ¬éªŒè¯å·¥ä½œæµ
"""

import asyncio
import json
import os
import sys
import time
from pathlib import Path
from typing import Literal

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from scripts.operators import Custom, ScEnsemble, Programmer
from scripts.async_llm import LLMsConfig, create_llm_instance
from benchmarks.gsm8k import GSM8KBenchmark

DatasetType = Literal["HumanEval", "MBPP", "GSM8K", "MATH", "HotpotQA", "DROP"]

# æœ€ä¼˜å·¥ä½œæµçš„prompt
MATH_SOLVE_PROMPT = """
You are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:

1. Read and understand the problem thoroughly.
2. Identify all key information, variables, and relationships.
3. Determine the appropriate mathematical concepts, formulas, or equations to use.
4. Solve the problem step-by-step, showing all your work clearly.
5. Double-check your calculations and reasoning at each step.
6. Provide a clear and concise final answer.

Format your answer as follows:
- Show each step of your solution process clearly.
- Clearly state your final answer at the end of your solution.
- Ensure that your final answer is a single numerical value without any units or additional text.

For example, if the final answer is 42.5, your response should end with just:
42.5

Here's the problem to solve:

"""

class OptimalWorkflow:
    """æœ€ä¼˜çš„GSM8Kå·¥ä½œæµ (å‡†ç¡®ç‡93.744%)"""
    
    def __init__(self, name: str, llm_config, dataset: DatasetType) -> None:
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        self.custom = Custom(self.llm)
        self.sc_ensemble = ScEnsemble(self.llm)

    async def __call__(self, problem: str):
        """æœ€ä¼˜å·¥ä½œæµå®ç° - ç®€åŒ–ç‰ˆæœ¬ç”¨äºå°è§„æ¨¡æµ‹è¯•"""
        solutions = []
        
        # åªç”Ÿæˆ3ä¸ªè§£å†³æ–¹æ¡ˆ (åŸæœ¬æ˜¯5ä¸ª)
        for i in range(3):
            print(f"    ç”Ÿæˆè§£å†³æ–¹æ¡ˆ {i+1}/3...")
            solution = await self.custom(input=problem, instruction=MATH_SOLVE_PROMPT)
            solutions.append(solution['response'])
            
            # æ·»åŠ å»¶è¿Ÿä»¥æ§åˆ¶RPM
            if i < 2:
                await asyncio.sleep(2)
        
        # ä½¿ç”¨è‡ªä¸€è‡´æ€§é›†æˆé€‰æ‹©æœ€ä½³ç­”æ¡ˆ
        print("    è¿›è¡Œè‡ªä¸€è‡´æ€§é›†æˆ...")
        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)
        
        return final_solution['response'], self.llm.get_usage_summary()["total_cost"]

async def test_gsm8k_small():
    """å°è§„æ¨¡æµ‹è¯•GSM8K"""
    print("ğŸš€ å¼€å§‹GSM8Kå°è§„æ¨¡æµ‹è¯• (5ä¸ªæ ·æœ¬)")
    print("=" * 50)
    
    # é…ç½®æ¨¡å‹
    models_config = LLMsConfig.default()
    llm_config = models_config.get('llama3-70b-8192')
    
    print(f"âœ… æ¨¡å‹é…ç½®: {llm_config.model}")
    print(f"ğŸ”§ APIé™åˆ¶: RPM=30, TPM=6000")
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = OptimalWorkflow(
        name="GSM8K_optimal", 
        llm_config=llm_config, 
        dataset="GSM8K"
    )
    
    # åˆ›å»ºbenchmark
    benchmark = GSM8KBenchmark(
        name="GSM8K", 
        file_path="data/datasets/gsm8k_test.jsonl",
        log_path="workspace/GSM8K_test"
    )
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print("ğŸ“‚ åŠ è½½GSM8Kæµ‹è¯•æ•°æ®...")
    all_data = await benchmark.load_data()
    total_samples = len(all_data)
    test_samples = 5  # åªæµ‹è¯•5ä¸ªæ ·æœ¬
    
    print(f"ğŸ“Š æµ‹è¯•é›†æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"ğŸ¯ å°è§„æ¨¡æµ‹è¯•æ ·æœ¬æ•°: {test_samples}")
    
    # ä½¿ç”¨å‰5ä¸ªæ ·æœ¬
    test_data = all_data[:test_samples]
    
    # ä¸²è¡Œå¤„ç†
    print(f"\nğŸ”„ å¼€å§‹å¤„ç† {test_samples} ä¸ªæ ·æœ¬...")
    start_time = time.time()
    results = []
    
    for i, sample in enumerate(test_data):
        try:
            print(f"\nğŸ”„ å¤„ç†æ ·æœ¬ {i+1}/{test_samples}:")
            print(f"   é—®é¢˜: {sample['question']}")
            
            # è°ƒç”¨å·¥ä½œæµ
            prediction, cost = await workflow(sample['question'])
            
            # è¯„ä¼°ç»“æœ
            expected = benchmark.extract_number(sample['answer'])
            predicted = benchmark.extract_number(prediction)
            score, _ = benchmark.calculate_score(expected, predicted)
            
            print(f"   é¢„æµ‹ç­”æ¡ˆ: {predicted}")
            print(f"   æ­£ç¡®ç­”æ¡ˆ: {expected}")
            print(f"   å¾—åˆ†: {score:.1f}")
            print(f"   æˆæœ¬: ${cost:.6f}")
            
            results.append({
                "sample_id": i,
                "question": sample['question'],
                "expected": expected,
                "predicted": predicted,
                "prediction_text": prediction,
                "score": score,
                "cost": cost
            })
            
            # æ·»åŠ å»¶è¿Ÿä»¥æ§åˆ¶APIä½¿ç”¨
            if i < test_samples - 1:
                print("   ç­‰å¾…3ç§’...")
                await asyncio.sleep(3)
                
        except Exception as e:
            print(f"âŒ æ ·æœ¬ {i+1} å¤„ç†å¤±è´¥: {str(e)}")
            results.append({
                "sample_id": i,
                "question": sample['question'],
                "error": str(e),
                "score": 0.0,
                "cost": 0.0
            })
    
    # è®¡ç®—æœ€ç»ˆç»“æœ
    final_scores = [r.get('score', 0) for r in results]
    final_costs = [r.get('cost', 0) for r in results]
    
    avg_score = sum(final_scores) / len(final_scores)
    total_cost = sum(final_costs)
    total_time = time.time() - start_time
    
    print("\n" + "=" * 50)
    print("ğŸ‰ GSM8Kå°è§„æ¨¡æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š æ ·æœ¬æ•°: {test_samples}")
    print(f"ğŸ¯ å‡†ç¡®ç‡: {avg_score:.4f} ({avg_score*100:.2f}%)")
    print(f"ğŸ’° æ€»æˆæœ¬: ${total_cost:.6f}")
    print(f"â±ï¸  æ€»ç”¨æ—¶: {total_time:.1f}ç§’")
    print(f"ğŸ”¥ ä¸è®ºæ–‡ç»“æœå¯¹æ¯”: è®ºæ–‡93.74% vs å½“å‰{avg_score*100:.2f}%")
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    for i, result in enumerate(results):
        if 'error' in result:
            print(f"  æ ·æœ¬{i+1}: âŒ é”™è¯¯ - {result['error']}")
        else:
            status = "âœ…" if result['score'] == 1.0 else "âŒ"
            print(f"  æ ·æœ¬{i+1}: {status} {result['predicted']} (æœŸæœ›: {result['expected']})")
    
    # ä¿å­˜ç»“æœ
    output_dir = Path("workspace/GSM8K_test")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    result_file = output_dir / f"small_test_results_{avg_score:.4f}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            "summary": {
                "total_samples": test_samples,
                "average_score": avg_score,
                "total_cost": total_cost,
                "total_time": total_time,
                "paper_score": 0.9374
            },
            "detailed_results": results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    if avg_score > 0.5:
        print(f"\nğŸš€ å°è§„æ¨¡æµ‹è¯•æˆåŠŸï¼å¯ä»¥è¿è¡Œå®Œæ•´çš„ä¸€åŠæ•°æ®æµ‹è¯•:")
        print("python test_gsm8k_half.py")
    else:
        print(f"\nâš ï¸  å°è§„æ¨¡æµ‹è¯•ç»“æœè¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥é…ç½®åå†è¿è¡Œå¤§è§„æ¨¡æµ‹è¯•")

if __name__ == "__main__":
    asyncio.run(test_gsm8k_small()) 