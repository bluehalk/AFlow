#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GSM8Kæ¶ˆèç ”ç©¶è„šæœ¬ - å¿«é€Ÿæµ‹è¯•ç‰ˆæœ¬ (5ä¸ªæ ·æœ¬)
å¯¹æ¯”ä¸‰ç§æ–¹æ³•ï¼šDirectIO, IO_with_optimal_instructions, OptimalWorkflow
é€‚é…APIé™åˆ¶: RPM=30, TPM=6000, TPD=500000
"""

import asyncio
import json
import os
import sys
import time
import pandas as pd
from pathlib import Path
from typing import Literal, Dict, List, Any
from datetime import datetime
import statistics

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.operators import Custom, ScEnsemble, Programmer
from scripts.async_llm import LLMsConfig, create_llm_instance
from benchmarks.gsm8k import GSM8KBenchmark

DatasetType = Literal["HumanEval", "MBPP", "GSM8K", "MATH", "HotpotQA", "DROP"]

# ä»round 10è·å–çš„æœ€ä¼˜prompt (æœ€ä½³æ€§èƒ½)
OPTIMAL_MATH_SOLVE_PROMPT = """You are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:

1. Read and understand the problem thoroughly.
2. Identify all key information, variables, and relationships.
3. Determine the appropriate mathematical concepts, formulas, or equations to use.
4. Solve the problem step-by-step, showing all your work clearly.
5. Double-check your calculations and reasoning at each step.
6. Provide a clear and concise final answer.
7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.

Format your answer as follows:
- Use LaTeX notation for mathematical expressions where appropriate.
- Show each step of your solution process clearly.
- Clearly state your final answer at the end of your solution.
- Express numerical answers as precise values (avoid rounding unless specified).
- Ensure that your final answer is a single numerical value without any units or additional text.
- Do not include any explanatory text with your final answer, just the number itself.

For example, if the final answer is 42.5, your response should end with just:
42.5

Here's the problem to solve:

"""

# åŸºç¡€çš„ç›´æ¥prompt (æœ€ç®€å•çš„baseline)
BASIC_SOLVE_PROMPT = """Solve this math problem step by step and provide the final numerical answer.

"""

# ä¸­ç­‰å¤æ‚åº¦çš„prompt
MEDIUM_SOLVE_PROMPT = """Solve this math problem step by step. Show your work and provide the final numerical answer.

"""

# ç®€å•æ•°å­¦prompt  
SIMPLE_MATH_PROMPT = """Solve this math problem:

"""

# æœ€ç®€å•çš„prompt
MINIMAL_PROMPT = """Answer:

"""

# ç©ºprompt (æ— æŒ‡å¯¼)
NO_PROMPT = ""

class DirectIO:
    """ç›´æ¥æŠŠé—®é¢˜ç»™LLM - æœ€åŸºç¡€çš„æ–¹æ³•"""
    
    def __init__(self, name: str, llm_config, dataset: DatasetType) -> None:
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        self.custom = Custom(self.llm)

    async def __call__(self, problem: str):
        """ç›´æ¥è°ƒç”¨LLMè§£å†³é—®é¢˜"""
        print(f"  DirectIO: ç›´æ¥æ±‚è§£é—®é¢˜...")
        solution = await self.custom(input=problem, instruction=BASIC_SOLVE_PROMPT)
        return solution['response'], self.llm.get_usage_summary()["total_cost"]

class IO_with_optimal_instructions:
    """ä½¿ç”¨æœ€ä¼˜instructionsçš„IO"""
    
    def __init__(self, name: str, llm_config, dataset: DatasetType) -> None:
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        self.custom = Custom(self.llm)

    async def __call__(self, problem: str):
        """ä½¿ç”¨æœ€ä¼˜promptç›´æ¥è°ƒç”¨LLM"""
        print(f"  IO_optimal: ä½¿ç”¨æœ€ä¼˜promptæ±‚è§£...")
        solution = await self.custom(input=problem, instruction=OPTIMAL_MATH_SOLVE_PROMPT)
        return solution['response'], self.llm.get_usage_summary()["total_cost"]

class OptimalWorkflow:
    """æœ€ä¼˜å·¥ä½œæµå®ç° - åŸºäºround 10çš„ç»“æœ"""
    
    def __init__(self, name: str, llm_config, dataset: DatasetType) -> None:
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        self.custom = Custom(self.llm)
        self.sc_ensemble = ScEnsemble(self.llm)
        self.programmer = Programmer(self.llm)

    async def __call__(self, problem: str):
        """æœ€ä¼˜å·¥ä½œæµå®ç°"""
        solutions = []
        
        # ç”Ÿæˆ2ä¸ªè§£å†³æ–¹æ¡ˆ (å¿«é€Ÿæµ‹è¯•ç‰ˆæœ¬ï¼Œå‡å°‘APIè°ƒç”¨)
        for i in range(2):
            print(f"  OptimalWorkflow: ç”Ÿæˆè§£å†³æ–¹æ¡ˆ {i+1}/2...")
            
            # å¸¦é‡è¯•çš„è§£å†³æ–¹æ¡ˆç”Ÿæˆ
            for attempt in range(3):
                try:
                    if attempt > 0:
                        print(f"    ğŸ”„ è§£å†³æ–¹æ¡ˆç”Ÿæˆé‡è¯•ç¬¬ {attempt} æ¬¡...")
                        await asyncio.sleep(2)
                    
                    solution = await self.custom(input=problem, instruction=OPTIMAL_MATH_SOLVE_PROMPT)
                    solutions.append(solution['response'])
                    break
                    
                except Exception as e:
                    error_msg = str(e).lower()
                    if any(keyword in error_msg for keyword in ['connection', 'timeout', 'network']):
                        if attempt < 2:
                            print(f"    âŒ ç”Ÿæˆè§£å†³æ–¹æ¡ˆç½‘ç»œé”™è¯¯ï¼Œå‡†å¤‡é‡è¯•: {e}")
                            continue
                    
                    print(f"    âŒ ç”Ÿæˆè§£å†³æ–¹æ¡ˆå¤±è´¥: {e}")
                    # å¦‚æœå¤±è´¥ï¼Œæ·»åŠ ä¸€ä¸ªé”™è¯¯æ ‡è®°
                    solutions.append(f"Error generating solution {i+1}: {e}")
                    break
            
            # æ·»åŠ å»¶è¿Ÿä»¥æ§åˆ¶RPM
            if i < 1:  # æœ€åä¸€ä¸ªä¸éœ€è¦å»¶è¿Ÿ
                await asyncio.sleep(2.5)
        
        # ä½¿ç”¨è‡ªä¸€è‡´æ€§é›†æˆé€‰æ‹©æœ€ä½³ç­”æ¡ˆ (å¸¦é‡è¯•æœºåˆ¶)
        print("  OptimalWorkflow: è¿›è¡Œè‡ªä¸€è‡´æ€§é›†æˆ...")
        final_solution = None
        for attempt in range(3):
            try:
                if attempt > 0:
                    print(f"    ğŸ”„ è‡ªä¸€è‡´æ€§é›†æˆé‡è¯•ç¬¬ {attempt} æ¬¡...")
                    await asyncio.sleep(2)
                
                final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)
                break
                
            except Exception as e:
                error_msg = str(e).lower()
                if any(keyword in error_msg for keyword in ['connection', 'timeout', 'network']):
                    if attempt < 2:
                        print(f"    âŒ è‡ªä¸€è‡´æ€§é›†æˆç½‘ç»œé”™è¯¯ï¼Œå‡†å¤‡é‡è¯•: {e}")
                        continue
                
                print(f"    âŒ è‡ªä¸€è‡´æ€§é›†æˆå¤±è´¥: {e}")
                # å¦‚æœè‡ªä¸€è‡´æ€§å¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆ
                valid_solutions = [s for s in solutions if not s.startswith("Error")]
                if valid_solutions:
                    final_solution = {'response': valid_solutions[0]}
                    print("  OptimalWorkflow: ä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆè§£å†³æ–¹æ¡ˆ")
                else:
                    final_solution = {'response': "æ‰€æœ‰è§£å†³æ–¹æ¡ˆç”Ÿæˆå¤±è´¥"}
                    print("  OptimalWorkflow: æ‰€æœ‰è§£å†³æ–¹æ¡ˆéƒ½å¤±è´¥äº†")
                break
        
        # æ£€æŸ¥final_solutionæ˜¯å¦æœ‰æ•ˆ
        if not final_solution or 'response' not in final_solution:
            print("  OptimalWorkflow: æ‰€æœ‰æ­¥éª¤éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯")
            return "OptimalWorkflowæ‰§è¡Œå¤±è´¥ï¼šæ— æ³•ç”Ÿæˆæœ‰æ•ˆè§£å†³æ–¹æ¡ˆ", 0.0
        
        # ä½¿ç”¨ç¼–ç¨‹å™¨éªŒè¯ (å¸¦é‡è¯•æœºåˆ¶)
        print("  OptimalWorkflow: ä»£ç éªŒè¯...")
        verification_success = False
        for attempt in range(3):
            try:
                if attempt > 0:
                    print(f"    ğŸ”„ éªŒè¯é‡è¯•ç¬¬ {attempt} æ¬¡...")
                    await asyncio.sleep(2)
                
                verification = await self.programmer(problem=problem, analysis=final_solution['response'])
                if verification['output']:
                    print("  OptimalWorkflow: éªŒè¯æˆåŠŸï¼Œä½¿ç”¨éªŒè¯ç»“æœ")
                    return verification['output'], self.llm.get_usage_summary()["total_cost"]
                else:
                    print("  OptimalWorkflow: éªŒè¯æ— è¾“å‡ºï¼Œä½¿ç”¨è‡ªä¸€è‡´æ€§ç»“æœ")
                    break
                    
            except Exception as e:
                error_msg = str(e).lower()
                if any(keyword in error_msg for keyword in ['connection', 'timeout', 'network']):
                    if attempt < 2:
                        print(f"    âŒ éªŒè¯ç½‘ç»œé”™è¯¯ï¼Œå‡†å¤‡é‡è¯•: {e}")
                        continue
                
                print(f"    éªŒè¯æ­¥éª¤å¤±è´¥ï¼Œä½¿ç”¨è‡ªä¸€è‡´æ€§ç»“æœ: {e}")
                break
        
        print("  OptimalWorkflow: ä½¿ç”¨è‡ªä¸€è‡´æ€§é›†æˆç»“æœ")
        return final_solution['response'], self.llm.get_usage_summary()["total_cost"]

class QuickAblationExperiment:
    """å¿«é€Ÿæ¶ˆèå®éªŒç®¡ç†å™¨ - 5ä¸ªæ ·æœ¬"""
    
    def __init__(self, data_file: str, results_dir: str = "z_ablation/results_quick"):
        self.data_file = data_file
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(exist_ok=True)
        
        # é…ç½®æ¨¡å‹
        self.models_config = LLMsConfig.default()
        self.llm_config = self.models_config.get('llama3-70b-8192')
        
        # åˆ›å»ºbenchmark
        self.benchmark = GSM8KBenchmark(
            name="GSM8K_Quick_Ablation", 
            file_path="data/datasets/gsm8k_test.jsonl",
            log_path="workspace/GSM8K_ablation_quick"
        )
        
        # å®éªŒè®°å½•
        self.experiment_log = {
            "start_time": datetime.now().isoformat(),
            "config": {
                "model": self.llm_config.model,
                "data_file": data_file,
                "api_limits": "RPM=30, TPM=6000, TPD=500000",
                "test_samples": 5,
                "note": "å¿«é€Ÿæµ‹è¯•ç‰ˆæœ¬"
            },
            "methods": {},
            "summary": {}
        }
    
    async def load_test_data(self) -> List[Dict]:
        """åŠ è½½æµ‹è¯•æ•°æ® - åªå–å‰5ä¸ª"""
        print(f"ğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®: {self.data_file} (å‰5ä¸ªæ ·æœ¬)")
        
        data = []
        with open(self.data_file, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= 5:  # åªå–å‰5ä¸ª
                    break
                if line.strip():
                    data.append(json.loads(line.strip()))
        
        print(f"ğŸ“Š åŠ è½½äº† {len(data)} ä¸ªæµ‹è¯•æ ·æœ¬ (å¿«é€Ÿæµ‹è¯•ç‰ˆæœ¬)")
        return data
    
    async def run_method(self, method_class, method_name: str, test_data: List[Dict]) -> Dict:
        """è¿è¡Œå•ä¸ªæ–¹æ³•çš„æµ‹è¯•"""
        print(f"\nğŸš€ å¼€å§‹æµ‹è¯•æ–¹æ³•: {method_name}")
        print("=" * 60)
        
        # åˆ›å»ºæ–¹æ³•å®ä¾‹
        method = method_class(
            name=f"GSM8K_{method_name}", 
            llm_config=self.llm_config, 
            dataset="GSM8K"
        )
        
        results = []
        start_time = time.time()
        
        # APIè°ƒç”¨é¢‘ç‡æ§åˆ¶ - å¿«é€Ÿæµ‹è¯•ç‰ˆæœ¬ä½¿ç”¨è¾ƒçŸ­å»¶è¿Ÿ
        if method_name == "OptimalWorkflow":
            request_delay = 5   # OptimalWorkflowéœ€è¦æ›´é•¿å»¶è¿Ÿ
        else:
            request_delay = 2   # å…¶ä»–æ–¹æ³•è¾ƒçŸ­å»¶è¿Ÿ
        
        for i, sample in enumerate(test_data):
            print(f"ğŸ”„ [{method_name}] å¤„ç†æ ·æœ¬ {i+1}/{len(test_data)}: {sample['question'][:50]}...")
            
            # ç®€å•é‡è¯•æœºåˆ¶
            success = False
            for attempt in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
                try:
                    if attempt > 0:
                        print(f"    ğŸ”„ é‡è¯•ç¬¬ {attempt} æ¬¡...")
                        await asyncio.sleep(2)  # ç®€å•å»¶è¿Ÿ2ç§’
                    
                    # è°ƒç”¨æ–¹æ³•
                    prediction, cost = await method(sample['question'])
                    
                    # è¯„ä¼°ç»“æœ
                    expected = self.benchmark.extract_number(sample['answer'])
                    predicted = self.benchmark.extract_number(prediction)
                    score, _ = self.benchmark.calculate_score(expected, predicted)
                    
                    result = {
                        "sample_id": i,
                        "question": sample['question'],
                        "expected": expected,
                        "predicted": predicted,
                        "prediction_text": prediction,
                        "score": score,
                        "cost": cost,
                        "correct": score > 0.5  # äºŒè¿›åˆ¶æ­£ç¡®æ€§
                    }
                    results.append(result)
                    
                    print(f"âœ… [{method_name}] æ ·æœ¬ {i+1} - å¾—åˆ†: {score:.1f}, æˆæœ¬: ${cost:.6f}")
                    success = True
                    break
                    
                except Exception as e:
                    error_msg = str(e).lower()
                    # åªå¯¹ç½‘ç»œç›¸å…³é”™è¯¯é‡è¯•
                    if any(keyword in error_msg for keyword in ['connection', 'timeout', 'network']):
                        if attempt < 2:  # è¿˜æœ‰é‡è¯•æœºä¼š
                            print(f"    âŒ ç½‘ç»œé”™è¯¯ï¼Œå‡†å¤‡é‡è¯•: {e}")
                            continue
                    
                    # éç½‘ç»œé”™è¯¯æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                    print(f"âŒ [{method_name}] æ ·æœ¬ {i+1} æœ€ç»ˆå¤±è´¥: {str(e)}")
                    result = {
                        "sample_id": i,
                        "question": sample['question'],
                        "error": str(e),
                        "score": 0.0,
                        "cost": 0.0,
                        "correct": False
                    }
                    results.append(result)
                    break
            
            # APIé™åˆ¶æ§åˆ¶
            if i < len(test_data) - 1:  # æœ€åä¸€ä¸ªä¸éœ€è¦å»¶è¿Ÿ
                await asyncio.sleep(request_delay)
        
        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        scores = [r['score'] for r in results]
        costs = [r['cost'] for r in results]
        correct_count = sum(1 for r in results if r['correct'])
        
        actual_samples = len(results)
        
        method_stats = {
            "method_name": method_name,
            "total_samples": actual_samples,
            "correct_samples": correct_count,
            "accuracy": correct_count / actual_samples,
            "avg_score": statistics.mean(scores),
            "score_std": statistics.stdev(scores) if len(scores) > 1 else 0,
            "total_cost": sum(costs),
            "avg_cost_per_sample": statistics.mean(costs),
            "total_time_seconds": total_time,
            "avg_time_per_sample": total_time / actual_samples,
            "detailed_results": results
        }
        
        print(f"\nğŸ“Š [{method_name}] æœ€ç»ˆç»“æœ:")
        print(f"   æ€»æ ·æœ¬æ•°: {method_stats['total_samples']}")
        print(f"   æ­£ç¡®æ ·æœ¬æ•°: {method_stats['correct_samples']}")
        print(f"   å‡†ç¡®ç‡: {method_stats['accuracy']:.1%}")
        print(f"   å¹³å‡å¾—åˆ†: {method_stats['avg_score']:.3f} Â± {method_stats['score_std']:.3f}")
        print(f"   æ€»æˆæœ¬: ${method_stats['total_cost']:.4f}")
        print(f"   å¹³å‡æ¯æ ·æœ¬æˆæœ¬: ${method_stats['avg_cost_per_sample']:.6f}")
        print(f"   æ€»ç”¨æ—¶: {method_stats['total_time_seconds']:.1f}ç§’")
        
        return method_stats
    
    async def run_ablation_study(self):
        """è¿è¡Œå®Œæ•´çš„æ¶ˆèç ”ç©¶"""
        print("ğŸ¯ å¼€å§‹GSM8Kå¿«é€Ÿæ¶ˆèç ”ç©¶ (5ä¸ªæ ·æœ¬)")
        print("=" * 70)
        print(f"âœ… æ¨¡å‹é…ç½®: {self.llm_config.model}")
        print(f"ğŸ”§ APIé™åˆ¶: RPM=30, TPM=6000, TPD=500000")
        print(f"ğŸ“ å®éªŒé¡ºåº: DirectIO â†’ IO_with_optimal_instructions â†’ OptimalWorkflow")
        print(f"âš¡ å¿«é€Ÿæµ‹è¯•æ¨¡å¼: åªæµ‹è¯•5ä¸ªæ ·æœ¬ä»¥éªŒè¯ä»£ç é€»è¾‘")
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_data = await self.load_test_data()
        
        # å®šä¹‰æµ‹è¯•æ–¹æ³• (æŒ‰æŒ‡å®šé¡ºåº)
        methods = [
            (DirectIO, "DirectIO"),
            (IO_with_optimal_instructions, "IO_with_optimal_instructions"),
            (OptimalWorkflow, "OptimalWorkflow")
        ]
        
        # ä¾æ¬¡è¿è¡Œæ¯ä¸ªæ–¹æ³•
        for i, (method_class, method_name) in enumerate(methods):
            print(f"\nğŸ”„ å¼€å§‹ç¬¬ {i+1}/3 ä¸ªæ–¹æ³•: {method_name}")
            method_stats = await self.run_method(method_class, method_name, test_data)
            self.experiment_log["methods"][method_name] = method_stats
            
            # æ–¹æ³•é—´çš„ç¼“å†²æ—¶é—´
            if i < len(methods) - 1:
                print(f"\nâ³ ç­‰å¾…5ç§’åç»§ç»­ä¸‹ä¸€ä¸ªæ–¹æ³•...")
                await asyncio.sleep(5)
        
        # ç”Ÿæˆæ€»ç»“
        await self.generate_summary()
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        await self.save_final_results()
        
        print(f"\nğŸ‰ å¿«é€Ÿæ¶ˆèç ”ç©¶å®Œæˆ! ç»“æœä¿å­˜åœ¨: {self.results_dir}")
    
    async def generate_summary(self):
        """ç”Ÿæˆå®éªŒæ€»ç»“"""
        methods = self.experiment_log["methods"]
        
        # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
        comparison = []
        for method_name, stats in methods.items():
            comparison.append({
                "Method": method_name,
                "Accuracy": f"{stats['accuracy']:.1%}",
                "Avg_Score": f"{stats['avg_score']:.3f}",
                "Score_Std": f"{stats['score_std']:.3f}",
                "Total_Cost": f"${stats['total_cost']:.4f}",
                "Avg_Cost_Per_Sample": f"${stats['avg_cost_per_sample']:.6f}",
                "Total_Time(s)": f"{stats['total_time_seconds']:.1f}",
                "Correct_Count": f"{stats['correct_samples']}/5"
            })
        
        self.experiment_log["summary"] = {
            "comparison_table": comparison,
            "end_time": datetime.now().isoformat()
        }
        
        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 70)
        print("ğŸ“‹ å¿«é€Ÿæ¶ˆèç ”ç©¶æ€»ç»“ (5ä¸ªæ ·æœ¬)")
        print("=" * 70)
        
        df_comparison = pd.DataFrame(comparison)
        print(df_comparison.to_string(index=False))
        
        print(f"\nâœ… ä»£ç éªŒè¯å®Œæˆ - æ‰€æœ‰æ–¹æ³•éƒ½èƒ½æ­£å¸¸è¿è¡Œ")
        print(f"ğŸ”„ ç°åœ¨å¯ä»¥è¿è¡Œå®Œæ•´çš„200æ ·æœ¬æµ‹è¯•: python z_ablation/test_gsm8k_200.py")
    
    async def save_final_results(self):
        """ä¿å­˜æœ€ç»ˆå®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜å®Œæ•´å®éªŒæ—¥å¿—
        log_file = self.results_dir / f"quick_ablation_experiment_{timestamp}.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(self.experiment_log, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜å¯¹æ¯”è¡¨æ ¼
        comparison_df = pd.DataFrame(self.experiment_log["summary"]["comparison_table"])
        comparison_file = self.results_dir / f"quick_method_comparison_{timestamp}.csv"
        comparison_df.to_csv(comparison_file, index=False, encoding='utf-8')
        
        print(f"ğŸ’¾ å¿«é€Ÿæµ‹è¯•ç»“æœå·²ä¿å­˜åˆ° {self.results_dir}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ GSM8Kå¿«é€Ÿæ¶ˆèç ”ç©¶ - 5ä¸ªæ ·æœ¬éªŒè¯")
    print("=" * 50)
    
    # åˆ›å»ºå®éªŒ
    experiment = QuickAblationExperiment(
        data_file="z_ablation/200_gsm8k.jsonl",
        results_dir="z_ablation/results_quick"
    )
    
    # è¿è¡Œæ¶ˆèç ”ç©¶
    await experiment.run_ablation_study()

if __name__ == "__main__":
    asyncio.run(main())