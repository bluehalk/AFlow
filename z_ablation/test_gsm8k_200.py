#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GSM8Kæ¶ˆèç ”ç©¶è„šæœ¬ - 200ä¸ªæµ‹è¯•æ ·æœ¬ - ä»˜è´¹APIç‰ˆæœ¬
åªæµ‹è¯•OptimalWorkflowæ–¹æ³•
é€‚é…ä»˜è´¹APIé™åˆ¶: RPM=100, RPD=50000, TPM=30000
"""

import asyncio
import json
import os
import sys
import time
import pandas as pd
from pathlib import Path
from typing import Literal, Dict, List, Any
from datetime import datetime
import statistics

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.operators import Custom, ScEnsemble, Programmer
from scripts.async_llm import LLMsConfig, create_llm_instance
from benchmarks.gsm8k import GSM8KBenchmark

DatasetType = Literal["HumanEval", "MBPP", "GSM8K", "MATH", "HotpotQA", "DROP"]

# ä»round 10è·å–çš„æœ€ä¼˜prompt (æœ€ä½³æ€§èƒ½)
OPTIMAL_MATH_SOLVE_PROMPT = """You are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:

1. Read and understand the problem thoroughly.
2. Identify all key information, variables, and relationships.
3. Determine the appropriate mathematical concepts, formulas, or equations to use.
4. Solve the problem step-by-step, showing all your work clearly.
5. Double-check your calculations and reasoning at each step.
6. Provide a clear and concise final answer.
7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.

Format your answer as follows:
- Use LaTeX notation for mathematical expressions where appropriate.
- Show each step of your solution process clearly.
- Clearly state your final answer at the end of your solution.
- Express numerical answers as precise values (avoid rounding unless specified).
- Ensure that your final answer is a single numerical value without any units or additional text.
- Do not include any explanatory text with your final answer, just the number itself.

For example, if the final answer is 42.5, your response should end with just:
42.5

Here's the problem to solve:

"""

class OptimalWorkflow:
    """æœ€ä¼˜å·¥ä½œæµå®ç° - åŸºäºround 10çš„ç»“æœ - ä»˜è´¹APIä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, name: str, llm_config, dataset: DatasetType, max_retries: int = 3) -> None:
        self.name = name
        self.dataset = dataset
        self.llm_config = llm_config
        self.max_retries = max_retries
        self.llm = create_llm_instance(llm_config)
        self.custom = Custom(self.llm)
        self.sc_ensemble = ScEnsemble(self.llm)
        self.programmer = Programmer(self.llm)

    async def _call_with_simple_retry(self, func, *args, **kwargs):
        """ç®€å•é‡è¯•è¾…åŠ©å‡½æ•° - ä»˜è´¹APIä¼˜åŒ–ç‰ˆæœ¬"""
        for attempt in range(self.max_retries):
            try:
                if attempt > 0:
                    await asyncio.sleep(1)  # ä»˜è´¹APIé‡è¯•å»¶è¿Ÿå‡å°‘
                return await func(*args, **kwargs)
            except Exception as e:
                error_msg = str(e).lower()
                if any(keyword in error_msg for keyword in ['connection', 'timeout', 'network', 'rate limit']):
                    if attempt < self.max_retries - 1:
                        print(f"    âš ï¸  APIé”™è¯¯ï¼Œé‡è¯•ä¸­: {e}")
                        continue
                raise e

    async def __call__(self, problem: str):
        """æœ€ä¼˜å·¥ä½œæµå®ç° - ä»˜è´¹APIä¼˜åŒ–ç‰ˆæœ¬"""
        solutions = []
        
        # ç”Ÿæˆ3ä¸ªè§£å†³æ–¹æ¡ˆ - å¹¶å‘æ‰§è¡Œä»¥æé«˜é€Ÿåº¦
        print(f"  OptimalWorkflow: å¹¶å‘ç”Ÿæˆ3ä¸ªè§£å†³æ–¹æ¡ˆ...")
        tasks = []
        for i in range(3):
            task = self._call_with_simple_retry(
                self.custom, input=problem, instruction=OPTIMAL_MATH_SOLVE_PROMPT
            )
            tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œï¼Œä½†æœ‰è½»å¾®å»¶è¿Ÿä»¥é¿å…ç¬é—´è¿‡å¤šè¯·æ±‚
        try:
            # ä½¿ç”¨gatherä½†æ·»åŠ çŸ­å»¶è¿Ÿ
            for i, task in enumerate(tasks):
                if i > 0:
                    await asyncio.sleep(0.3)  # ä»˜è´¹APIå¯ä»¥æ›´å¿«
                solutions.append(await task)
            
            # æå–å“åº”
            solution_texts = [sol['response'] for sol in solutions]
            
        except Exception as e:
            print(f"    âŒ è§£å†³æ–¹æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            # é™çº§åˆ°é¡ºåºæ‰§è¡Œ
            solution_texts = []
            for i in range(3):
                try:
                    solution = await self._call_with_simple_retry(
                        self.custom, input=problem, instruction=OPTIMAL_MATH_SOLVE_PROMPT
                    )
                    solution_texts.append(solution['response'])
                except Exception as e:
                    print(f"    è§£å†³æ–¹æ¡ˆ{i+1}ç”Ÿæˆå¤±è´¥: {e}")
                    solution_texts.append(f"Error: {e}")
                
                if i < 2:
                    await asyncio.sleep(0.5)
        
        # ä½¿ç”¨è‡ªä¸€è‡´æ€§é›†æˆ
        print("  OptimalWorkflow: è¿›è¡Œè‡ªä¸€è‡´æ€§é›†æˆ...")
        valid_solutions = [s for s in solution_texts if not str(s).startswith("Error")]
        if not valid_solutions:
            print("    âŒ æ²¡æœ‰æœ‰æ•ˆè§£å†³æ–¹æ¡ˆè¿›è¡Œé›†æˆ")
            return "OptimalWorkflowæ‰§è¡Œå¤±è´¥", 0.0
            
        try:
            final_solution = await self._call_with_simple_retry(
                self.sc_ensemble, solutions=valid_solutions, problem=problem
            )
            print(f"    âœ… é›†æˆæˆåŠŸ: {final_solution['response'][:80]}...")
        except Exception as e:
            print(f"    âš ï¸  è‡ªä¸€è‡´æ€§é›†æˆå¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆè§£å†³æ–¹æ¡ˆ: {e}")
            final_solution = {'response': valid_solutions[0]}
        
        # ç¼–ç¨‹å™¨éªŒè¯
        print("  OptimalWorkflow: ä»£ç éªŒè¯...")
        try:
            verification = await self._call_with_simple_retry(
                self.programmer, problem=problem, analysis=final_solution['response']
            )
            # æ£€æŸ¥éªŒè¯ç»“æœæ˜¯å¦æœ‰æ•ˆ
            output = verification.get('output', '')
            if output and not str(output).startswith("Error") and str(output).strip():
                print(f"    âœ… éªŒè¯æˆåŠŸï¼Œä½¿ç”¨ä»£ç ç»“æœ: {output}")
                return str(output).strip(), self.llm.get_usage_summary()["total_cost"]
            else:
                print(f"    âš ï¸  éªŒè¯ç»“æœæ— æ•ˆï¼Œä½¿ç”¨è‡ªä¸€è‡´æ€§ç»“æœ: {output}")
        except Exception as e:
            print(f"    âŒ éªŒè¯å¤±è´¥ï¼Œä½¿ç”¨è‡ªä¸€è‡´æ€§ç»“æœ: {e}")
        
        return final_solution['response'], self.llm.get_usage_summary()["total_cost"]

class OptimalWorkflowExperiment:
    """OptimalWorkflowå®éªŒç®¡ç†å™¨ - ä»˜è´¹APIç‰ˆæœ¬"""
    
    def __init__(self, data_file: str, results_dir: str = "results", llm_config: str = "meta-llama/llama-3-70b-instruct"):
        self.data_file = data_file
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # é…ç½®æ¨¡å‹
        self.models_config = LLMsConfig.default()
        self.llm_config = self.models_config.get(llm_config)
        
        # åˆ›å»ºbenchmark
        self.benchmark = GSM8KBenchmark(
            name="GSM8K_OptimalWorkflow", 
            file_path="data/datasets/gsm8k_test.jsonl",
            log_path="workspace/GSM8K_optimal"
        )
        
        # å®éªŒè®°å½•
        self.experiment_log = {
            "start_time": datetime.now().isoformat(),
            "config": {
                "model": self.llm_config.model,
                "data_file": data_file,
                "api_limits": "RPM=100, RPD=50000, TPM=30000 (ä»˜è´¹API)",
                "total_samples": 200,
                "max_retries": 3,
                "optimization": "å¹¶å‘è§£å†³æ–¹æ¡ˆç”Ÿæˆï¼Œå‡å°‘å»¶è¿Ÿ",
                "method": "OptimalWorkflow only"
            },
            "results": {},
            "failed_samples": []
        }
    
    async def load_test_data(self) -> List[Dict]:
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        print(f"ğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®: {self.data_file}")
        
        data = []
        with open(self.data_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line.strip()))
        
        print(f"ğŸ“Š åŠ è½½äº† {len(data)} ä¸ªæµ‹è¯•æ ·æœ¬")
        if len(data) != 200:
            print(f"âš ï¸  è­¦å‘Š: æœŸæœ›200ä¸ªæ ·æœ¬ï¼Œå®é™…åŠ è½½äº†{len(data)}ä¸ª")
        return data
    
    async def run_optimal_workflow(self, test_data: List[Dict]) -> Dict:
        """è¿è¡ŒOptimalWorkflowæµ‹è¯• - ä»˜è´¹APIä¼˜åŒ–ç‰ˆæœ¬"""
        method_name = "OptimalWorkflow"
        print(f"\nğŸš€ å¼€å§‹æµ‹è¯•æ–¹æ³•: {method_name} (ä»˜è´¹APIä¼˜åŒ–ç‰ˆæœ¬)")
        print("=" * 60)
        
        # åˆ›å»ºæ–¹æ³•å®ä¾‹
        method = OptimalWorkflow(
            name=f"GSM8K_{method_name}", 
            llm_config=self.llm_config, 
            dataset="GSM8K",
            max_retries=3
        )
        
        results = []
        failed_samples = []
        start_time = time.time()
        
        # ä»˜è´¹APIçš„å»¶è¿Ÿé…ç½® - å¤§å¹…åº¦å‡å°‘å»¶è¿Ÿ
        # RPM=100æ„å‘³ç€æ¯0.6ç§’ä¸€ä¸ªè¯·æ±‚ï¼Œä½†OptimalWorkflowå†…éƒ¨æœ‰çº¦5ä¸ªè¯·æ±‚
        # æ‰€ä»¥æ¯ä¸ªæ ·æœ¬å¤§çº¦éœ€è¦3ç§’ï¼Œä¸ºäº†å®‰å…¨èµ·è§è®¾ç½®4ç§’å»¶è¿Ÿ
        request_delay = 4.0  # ç›¸æ¯”å…è´¹ç‰ˆæœ¬çš„10ç§’å¤§å¹…å‡å°‘
        
        for i, sample in enumerate(test_data):
            sample_start_time = time.time()
            try:
                print(f"ğŸ”„ [OptimalWorkflow] å¤„ç†æ ·æœ¬ {i+1}/{len(test_data)}: {sample['question'][:50]}...")
                
                # è°ƒç”¨æ–¹æ³•
                prediction, cost = await method(sample['question'])
                
                # è¯„ä¼°ç»“æœ
                expected = self.benchmark.extract_number(sample['answer'])
                predicted = self.benchmark.extract_number(prediction)
                score, _ = self.benchmark.calculate_score(expected, predicted)
                
                result = {
                    "sample_id": i,
                    "question": sample['question'],
                    "expected": expected,
                    "predicted": predicted,
                    "prediction_text": prediction,
                    "score": score,
                    "cost": cost,
                    "correct": score > 0.5,
                    "processing_time": time.time() - sample_start_time
                }
                results.append(result)
                
                print(f"âœ… [OptimalWorkflow] æ ·æœ¬ {i+1} - å¾—åˆ†: {score:.1f}, æˆæœ¬: ${cost:.6f}, ç”¨æ—¶: {result['processing_time']:.1f}s")
                
            except Exception as e:
                processing_time = time.time() - sample_start_time
                error_msg = str(e)
                
                print(f"âŒ [OptimalWorkflow] æ ·æœ¬ {i+1} æœ€ç»ˆå¤±è´¥: {error_msg}")
                
                failed_sample = {
                    "sample_id": i,
                    "question": sample['question'],
                    "error": error_msg,
                    "processing_time": processing_time
                }
                failed_samples.append(failed_sample)
                
                result = {
                    "sample_id": i,
                    "question": sample['question'],
                    "error": error_msg,
                    "score": 0.0,
                    "cost": 0.0,
                    "correct": False,
                    "processing_time": processing_time
                }
                results.append(result)
            
            # APIé™åˆ¶æ§åˆ¶ - ä»˜è´¹ç‰ˆæœ¬å»¶è¿Ÿå¤§å¹…å‡å°‘
            if i < len(test_data) - 1:
                await asyncio.sleep(request_delay)
            
            # æ¯10ä¸ªæ ·æœ¬æ˜¾ç¤ºè¿›åº¦ (é¢‘ç‡æé«˜)
            if (i + 1) % 10 == 0:
                successful_results = [r for r in results if 'error' not in r]
                if successful_results:
                    avg_score = sum(r['score'] for r in successful_results) / len(successful_results)
                    total_cost = sum(r['cost'] for r in results)
                    elapsed_time = time.time() - start_time
                    estimated_total_time = elapsed_time * len(test_data) / (i + 1)
                    remaining_time = estimated_total_time - elapsed_time
                    print(f"ğŸ“ˆ [OptimalWorkflow] è¿›åº¦: {i+1}/{len(test_data)}, å‡†ç¡®ç‡: {avg_score:.2f}, æˆæœ¬: ${total_cost:.3f}")
                    print(f"â±ï¸  å·²ç”¨æ—¶: {elapsed_time/60:.1f}åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {remaining_time/60:.1f}åˆ†é’Ÿ")
        
        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        successful_results = [r for r in results if 'error' not in r]
        
        if successful_results:
            scores = [r['score'] for r in successful_results]
            costs = [r['cost'] for r in results]
            correct_count = sum(1 for r in successful_results if r['correct'])
            
            method_stats = {
                "method_name": method_name,
                "total_samples": len(results),
                "successful_samples": len(successful_results),
                "failed_samples": len(failed_samples),
                "correct_samples": correct_count,
                "accuracy": correct_count / len(successful_results) if successful_results else 0,
                "overall_success_rate": len(successful_results) / len(results),
                "avg_score": statistics.mean(scores) if scores else 0,
                "score_std": statistics.stdev(scores) if len(scores) > 1 else 0,
                "total_cost": sum(costs),
                "avg_cost_per_sample": statistics.mean(costs) if costs else 0,
                "total_time_seconds": total_time,
                "total_time_minutes": total_time / 60,
                "avg_time_per_sample": total_time / len(results),
                "detailed_results": results
            }
        else:
            method_stats = {
                "method_name": method_name,
                "total_samples": len(results),
                "successful_samples": 0,
                "failed_samples": len(failed_samples),
                "correct_samples": 0,
                "accuracy": 0,
                "overall_success_rate": 0,
                "avg_score": 0,
                "score_std": 0,
                "total_cost": 0,
                "avg_cost_per_sample": 0,
                "total_time_seconds": total_time,
                "total_time_minutes": total_time / 60,
                "avg_time_per_sample": total_time / len(results),
                "detailed_results": results
            }
        
        # è®°å½•å¤±è´¥çš„æ ·æœ¬
        if failed_samples:
            self.experiment_log["failed_samples"] = failed_samples
        
        print(f"\nğŸ“Š [OptimalWorkflow] æœ€ç»ˆç»“æœ:")
        print(f"   å‡†ç¡®ç‡: {method_stats['accuracy']:.1%} ({method_stats['correct_samples']}/200)")
        if method_stats['failed_samples'] > 0:
            print(f"   å¤±è´¥æ ·æœ¬: {method_stats['failed_samples']}")
        print(f"   æ€»æˆæœ¬: ${method_stats['total_cost']:.4f}")
        print(f"   ç”¨æ—¶: {method_stats['total_time_minutes']:.1f}åˆ†é’Ÿ")
        
        return method_stats
    
    async def run_experiment(self):
        """è¿è¡ŒOptimalWorkflowå®éªŒ"""
        print("ğŸ¯ å¼€å§‹OptimalWorkflowå®éªŒ (200ä¸ªæ ·æœ¬, ä»˜è´¹API)")
        print("=" * 60)
        print(f"âœ… æ¨¡å‹é…ç½®: {self.llm_config.model}")
        print(f"ğŸ”§ APIé™åˆ¶: RPM=100, RPD=50000, TPM=30000 (ä»˜è´¹API)")
        print(f"ğŸš€ ä¼˜åŒ–: å¹¶å‘è§£å†³æ–¹æ¡ˆç”Ÿæˆï¼Œå»¶è¿Ÿå‡å°‘60%")
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_data = await self.load_test_data()
        
        # è¿è¡ŒOptimalWorkflow
        method_stats = await self.run_optimal_workflow(test_data)
        self.experiment_log["results"] = method_stats
        
        # ä¿å­˜ç»“æœ
        await self.save_results()
        
        print(f"\nğŸ‰ OptimalWorkflowå®éªŒå®Œæˆ! ç»“æœä¿å­˜åœ¨: {self.results_dir}")
    
    async def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜è¯¦ç»†ç»“æœåˆ°CSV
        df = pd.DataFrame(self.experiment_log["results"]["detailed_results"])
        csv_file = self.results_dir / f"OptimalWorkflow_paid_{timestamp}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        # ä¿å­˜å®Œæ•´å®éªŒæ—¥å¿—
        log_file = self.results_dir / f"OptimalWorkflow_experiment_paid_{timestamp}.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(self.experiment_log, f, ensure_ascii=False, indent=2)
        
        # å¦‚æœæœ‰å¤±è´¥çš„æ ·æœ¬ï¼Œå•ç‹¬ä¿å­˜
        if self.experiment_log["failed_samples"]:
            failed_samples_file = self.results_dir / f"OptimalWorkflow_failed_samples_paid_{timestamp}.json"
            with open(failed_samples_file, 'w', encoding='utf-8') as f:
                json.dump(self.experiment_log["failed_samples"], f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° {self.results_dir}")
        print(f"ğŸ“ è¯¦ç»†ç»“æœ: OptimalWorkflow_paid_{timestamp}.csv")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ GSM8K OptimalWorkflowå®éªŒ - 200ä¸ªæ ·æœ¬ (ä»˜è´¹API)")
    print("=" * 60)
    
    # åˆ›å»ºå®éªŒ
    experiment = OptimalWorkflowExperiment(
        data_file="z_ablation/200_gsm8k.jsonl",
        results_dir="z_ablation/results",
        llm_config="meta-llama/llama-3-70b-instruct"  # ä»˜è´¹APIé…ç½®
    )
    
    # è¿è¡Œå®éªŒ
    await experiment.run_experiment()

if __name__ == "__main__":
    asyncio.run(main())