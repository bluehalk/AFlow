#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MBPP Graph Workflow æµ‹è¯•è„šæœ¬ - å®Œå…¨å¤åˆ¶graph.pyçš„å®ç°
åŒ…æ‹¬å®Œæ•´çš„tokenç»Ÿè®¡å’Œ5æ¬¡è°ƒç”¨è¿½è¸ª
"""

import asyncio
import json
import os
import sys
import time
from pathlib import Path
from typing import Literal, Dict, List, Any
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import scripts.operators as operator
from scripts.async_llm import create_llm_instance, LLMsConfig

DatasetType = Literal["HumanEval", "MBPP", "GSM8K", "MATH", "HotpotQA", "DROP"]

# ä½¿ç”¨å’Œgraph.pyç›¸åŒçš„prompt (ä»åŸå§‹prompt.pyå¤åˆ¶)
CODE_GENERATE_PROMPT = """
Generate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.

Problem:
{problem}

Function signature:
{entry_point}

Generate the complete function below:
"""

FIX_CODE_PROMPT = """
The provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.

Problem:
{input}

Provide the corrected function below:
"""

class TokenTracker:
    """Tokenä½¿ç”¨ç»Ÿè®¡å™¨"""
    def __init__(self):
        self.reset()
    
    def reset(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.calls = []
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.total_tokens = 0
        self.total_cost = 0.0
    
    def add_call(self, operation: str, input_tokens: int, output_tokens: int, cost: float):
        """æ·»åŠ ä¸€æ¬¡è°ƒç”¨çš„ç»Ÿè®¡"""
        self.calls.append({
            "operation": operation,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "total_tokens": input_tokens + output_tokens,
            "cost": cost
        })
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens
        self.total_tokens += input_tokens + output_tokens
        self.total_cost += cost
    
    def get_summary(self):
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        return {
            "total_calls": len(self.calls),
            "total_input_tokens": self.total_input_tokens,
            "total_output_tokens": self.total_output_tokens,
            "total_tokens": self.total_tokens,
            "total_cost": self.total_cost,
            "calls_detail": self.calls
        }

class Workflow:
    """å®Œå…¨å¤åˆ¶graph.pyçš„Workflowç±»"""
    def __init__(
        self,
        name: str,
        llm_config,
        dataset: DatasetType,
    ) -> None:
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        self.custom = operator.Custom(self.llm)
        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)
        self.test = operator.Test(self.llm)
        self.sc_ensemble = operator.ScEnsemble(self.llm)
        
        # æ·»åŠ tokenè¿½è¸ªå™¨
        self.token_tracker = TokenTracker()

    def _get_tokens_and_cost(self):
        """è·å–å½“å‰çš„tokenså’Œcost"""
        if hasattr(self.llm, 'usage_tracker'):
            return (
                self.llm.usage_tracker.total_input_tokens,
                self.llm.usage_tracker.total_output_tokens, 
                self.llm.usage_tracker.total_cost
            )
        else:
            return 0, 0, 0.0
    
    def _track_operation(self, operation: str, initial_input: int, initial_output: int, initial_cost: float):
        """è¿½è¸ªä¸€æ¬¡æ“ä½œçš„tokenä½¿ç”¨"""
        current_input, current_output, current_cost = self._get_tokens_and_cost()
        delta_input = current_input - initial_input
        delta_output = current_output - initial_output
        delta_cost = current_cost - initial_cost
        
        self.token_tracker.add_call(operation, delta_input, delta_output, delta_cost)
        return delta_input, delta_output, delta_cost

    async def __call__(self, problem: str, entry_point: str):
        """
        Implementation of the graph - å®Œå…¨å¤åˆ¶åŸå§‹graph.py
        Custom operator to generate anything you want.
        But when you want to get standard code, you should use custom_code_generate operator.
        """
        print(f"    ğŸ”„ å¼€å§‹Graph workflow: {entry_point}")
        
        # é‡ç½®tokenè¿½è¸ªå™¨
        self.token_tracker.reset()
        
        # ç¬¬1-3æ¬¡è°ƒç”¨: Generate 3 solutions
        print(f"    ğŸ“ ç”Ÿæˆ3ä¸ªè§£å†³æ–¹æ¡ˆ...")
        solutions = [] 
        for i in range(3):
            initial_input, initial_output, initial_cost = self._get_tokens_and_cost()
            
            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=CODE_GENERATE_PROMPT)
            # CustomCodeGenerate returns {'code': '...'}, not {'response': '...'}
            solutions.append(solution['code'])
            
            # è¿½è¸ªæ­¤æ¬¡è°ƒç”¨
            self._track_operation(f"CustomCodeGenerate_{i+1}", initial_input, initial_output, initial_cost)
            print(f"      âœ… è§£å†³æ–¹æ¡ˆ {i+1} ç”Ÿæˆå®Œæˆ")
        
        # ç¬¬4æ¬¡è°ƒç”¨: Self-consistency ensemble
        print(f"    ğŸ”„ è‡ªä¸€è‡´æ€§é›†æˆ...")
        initial_input, initial_output, initial_cost = self._get_tokens_and_cost()
        
        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)
        
        # è¿½è¸ªScEnsembleè°ƒç”¨
        self._track_operation("ScEnsemble", initial_input, initial_output, initial_cost)
        
        # Ensure sc_ensemble returned correct format
        if not isinstance(best_solution, dict) or 'response' not in best_solution:
            # Fallback to first solution
            best_solution = {"response": solutions[0]}
        
        # Test the solution
        print(f"    ğŸ§ª æµ‹è¯•è§£å†³æ–¹æ¡ˆ...")
        try:
            test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)
        except Exception as e:
            print(f"    âš ï¸ æµ‹è¯•è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}")
            # If test fails, return the solution without testing
            test_result = {"result": False, "solution": best_solution['response']}
        
        if test_result['result']:
            print(f"    âœ… æµ‹è¯•é€šè¿‡!")
            return test_result['solution'], self.llm.usage_tracker.total_cost
        else:
            # ç¬¬5æ¬¡è°ƒç”¨: If the test fails, try to fix the solution
            print(f"    ğŸ”§ æµ‹è¯•å¤±è´¥ï¼Œå°è¯•ä¿®å¤è§£å†³æ–¹æ¡ˆ...")
            try:
                initial_input, initial_output, initial_cost = self._get_tokens_and_cost()
                
                fixed_solution = await self.custom(input=f"Problem: {problem}\nFailed solution: {best_solution['response']}\nError: {test_result['solution']}", instruction=FIX_CODE_PROMPT)
                
                # è¿½è¸ªCustomä¿®å¤è°ƒç”¨
                self._track_operation("Custom_Fix", initial_input, initial_output, initial_cost)
                
                print(f"    âœ… ä¿®å¤å®Œæˆ")
                return fixed_solution['response'], self.llm.usage_tracker.total_cost
            except Exception as e:
                print(f"    âŒ ä¿®å¤å¤±è´¥: {str(e)}")
                # If fix also fails, return the original solution
                return best_solution['response'], self.llm.usage_tracker.total_cost

class MBPPTestExperiment:
    """MBPPæµ‹è¯•å®éªŒç®¡ç†å™¨"""
    
    def __init__(self, llm_config: str = "openai/gpt-4o-mini"):
        # é…ç½®æ¨¡å‹
        self.models_config = LLMsConfig.default()
        self.llm_config = self.models_config.get(llm_config)
        
        if self.llm_config is None:
            raise ValueError(f"Model '{llm_config}' not found in configuration")
    
    async def test_single_problem(self, problem_data: Dict):
        """æµ‹è¯•å•ä¸ªé—®é¢˜"""
        problem = problem_data.get('prompt', problem_data.get('text', ''))
        entry_point = problem_data.get('entry_point', '')
        test_cases = problem_data.get('test_list', problem_data.get('test', []))
        
        print(f"\nğŸ¯ æµ‹è¯•é—®é¢˜: {entry_point}")
        print(f"ğŸ“ é—®é¢˜æè¿°: {problem[:100]}...")
        print(f"ğŸ§ª æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(test_cases) if isinstance(test_cases, list) else 'N/A'}")
        
        # åˆ›å»ºworkflow
        workflow = Workflow(
            name="MBPP_Graph_Test",
            llm_config=self.llm_config,
            dataset="MBPP"
        )
        
        start_time = time.time()
        
        try:
            # è¿è¡Œworkflow
            result, cost = await workflow(problem, entry_point)
            
            processing_time = time.time() - start_time
            
            # è·å–è¯¦ç»†çš„tokenç»Ÿè®¡
            token_summary = workflow.token_tracker.get_summary()
            
            # print(f"\nğŸ“Š ç»“æœç»Ÿè®¡:")
            # print(f"   âœ… å¤„ç†å®Œæˆ!")
            # print(f"   ğŸ’° æ€»æˆæœ¬: ${cost:.6f}")
            # print(f"   ğŸ• å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
            # print(f"   ğŸ“ æ€»è°ƒç”¨æ¬¡æ•°: {token_summary['total_calls']}")
            # print(f"   ğŸ“ˆ æ€»Input tokens: {token_summary['total_input_tokens']:,}")
            # print(f"   ğŸ“‰ æ€»Output tokens: {token_summary['total_output_tokens']:,}")
            # print(f"   ğŸ“Š æ€»tokens: {token_summary['total_tokens']:,}") 
            
            # print(f"\nğŸ“‹ è¯¦ç»†è°ƒç”¨ç»Ÿè®¡:")
            # for i, call in enumerate(token_summary['calls_detail'], 1):
            #     print(f"   {i}. {call['operation']}:")
            #     print(f"      Input: {call['input_tokens']:,}, Output: {call['output_tokens']:,}, Total: {call['total_tokens']:,}")
            #     print(f"      Cost: ${call['cost']:.6f}")
            
            print(f"\nğŸ”§ ç”Ÿæˆçš„æœ€ç»ˆä»£ç :")
            print("="*60)
            print(result)
            print("="*60)
            
            return {
                "success": test_result['result'],
                "result": result,
                "cost": cost,
                "processing_time": processing_time,
                "token_summary": token_summary,
                "entry_point": entry_point
            }
            
        except Exception as e:
            processing_time = time.time() - start_time
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            
            return {
                "success": False,
                "error": str(e),
                "processing_time": processing_time,
                "entry_point": entry_point
            }
    
    async def test_multiple_problems(self, max_samples: int = 3):
        """æµ‹è¯•å¤šä¸ªé—®é¢˜"""
        print(f"ğŸš€ å¼€å§‹MBPP Graph Workflowæµ‹è¯• - æœ€å¤š{max_samples}ä¸ªæ ·æœ¬")
        print("="*80)
        
        # å°è¯•ä¸åŒçš„æ•°æ®æ–‡ä»¶
        data_files = [
            "data/datasets/mbpp_test.jsonl", 
        ]
        
        test_data = []
        for data_file in data_files:
            try:
                with open(data_file, 'r', encoding='utf-8') as f:
                    for i, line in enumerate(f):
                        if i >= max_samples:
                            break
                        if line.strip():
                            test_data.append(json.loads(line.strip()))
                print(f"ğŸ“‚ æˆåŠŸåŠ è½½ {data_file}")
                break
            except FileNotFoundError:
                continue
        
        if not test_data:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶!")
            return []
        
        print(f"ğŸ“‚ åŠ è½½äº† {len(test_data)} ä¸ªæµ‹è¯•æ ·æœ¬")
        
        results = []
        total_start_time = time.time()
        
        for i, sample in enumerate(test_data):
            print(f"\n{'='*20} æ ·æœ¬ {i+1}/{len(test_data)} {'='*20}")
            
            result = await self.test_single_problem(sample)
            results.append(result)
            
            # æ˜¾ç¤ºç´¯è®¡ç»Ÿè®¡
            successful_results = [r for r in results if r['success']]
            if successful_results:
                total_cost = sum(r['cost'] for r in successful_results)
                total_calls = sum(r['token_summary']['total_calls'] for r in successful_results)
                total_input_tokens = sum(r['token_summary']['total_input_tokens'] for r in successful_results)
                total_output_tokens = sum(r['token_summary']['total_output_tokens'] for r in successful_results)
                total_tokens = sum(r['token_summary']['total_tokens'] for r in successful_results)
                
                print(f"\nğŸ“ˆ ç´¯è®¡ç»Ÿè®¡ ({i+1}/{len(test_data)}):")
                print(f"   æˆåŠŸ: {len(successful_results)}, å¤±è´¥: {len(results) - len(successful_results)}")
                print(f"   æ€»è°ƒç”¨: {total_calls}")
                print(f"   æ€»æˆæœ¬: ${total_cost:.6f}")
                print(f"   æ€»Input tokens: {total_input_tokens:,}")
                print(f"   æ€»Output tokens: {total_output_tokens:,}")
                print(f"   æ€»tokens: {total_tokens:,}")
        
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - total_start_time
        successful_results = [r for r in results if r['success']]
        
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ! æ€»ç”¨æ—¶: {total_time/60:.2f}åˆ†é’Ÿ")
        print("="*80)
        print("ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬: {len(results)}")
        print(f"   æˆåŠŸ: {len(successful_results)}")
        print(f"   å¤±è´¥: {len(results) - len(successful_results)}")
        
        if successful_results:
            total_cost = sum(r['cost'] for r in successful_results)
            total_calls = sum(r['token_summary']['total_calls'] for r in successful_results)
            total_input_tokens = sum(r['token_summary']['total_input_tokens'] for r in successful_results)
            total_output_tokens = sum(r['token_summary']['total_output_tokens'] for r in successful_results)
            total_tokens = sum(r['token_summary']['total_tokens'] for r in successful_results)
            avg_time = sum(r['processing_time'] for r in successful_results) / len(successful_results)
            
            print(f"   æ€»è°ƒç”¨: {total_calls} (å¹³å‡ {total_calls/len(successful_results):.1f}/æ ·æœ¬)")
            print(f"   æ€»æˆæœ¬: ${total_cost:.6f}")
            print(f"   å¹³å‡æˆæœ¬/æ ·æœ¬: ${total_cost/len(successful_results):.6f}")
            print(f"   æ€»Input tokens: {total_input_tokens:,}")
            print(f"   æ€»Output tokens: {total_output_tokens:,}")
            print(f"   æ€»tokens: {total_tokens:,}")
            print(f"   å¹³å‡tokens/æ ·æœ¬: {total_tokens/len(successful_results):.0f}")
            print(f"   å¹³å‡å¤„ç†æ—¶é—´/æ ·æœ¬: {avg_time:.2f}ç§’")
            
            # æ˜¾ç¤ºæ¯ç§æ“ä½œçš„ç»Ÿè®¡
            print(f"\nğŸ“‹ æ“ä½œç±»å‹ç»Ÿè®¡:")
            operation_stats = {}
            for result in successful_results:
                for call in result['token_summary']['calls_detail']:
                    op = call['operation']
                    if op not in operation_stats:
                        operation_stats[op] = {'count': 0, 'input_tokens': 0, 'output_tokens': 0, 'cost': 0.0}
                    operation_stats[op]['count'] += 1
                    operation_stats[op]['input_tokens'] += call['input_tokens']
                    operation_stats[op]['output_tokens'] += call['output_tokens']
                    operation_stats[op]['cost'] += call['cost']
            
            for op, stats in operation_stats.items():
                avg_input = stats['input_tokens'] / stats['count']
                avg_output = stats['output_tokens'] / stats['count']
                avg_cost = stats['cost'] / stats['count']
                print(f"   {op}: {stats['count']}æ¬¡")
                print(f"     å¹³å‡Input: {avg_input:.0f}, å¹³å‡Output: {avg_output:.0f}")
                print(f"     å¹³å‡æˆæœ¬: ${avg_cost:.6f}")
        
        return results

async def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    max_samples = 3  # é»˜è®¤æµ‹è¯•3ä¸ªæ ·æœ¬
    
    if len(sys.argv) > 1:
        try:
            max_samples = int(sys.argv[1])
        except ValueError:
            print("ç”¨æ³•: python test_mbpp_graph.py [max_samples]")
            print("  max_samples: æœ€å¤§æµ‹è¯•æ ·æœ¬æ•° (é»˜è®¤3)")
            return
    
    print(f"ğŸ¯ MBPP Graph Workflow æµ‹è¯•")
    print(f"ğŸ“‹ å®Œå…¨å¤åˆ¶ graph.py çš„å®ç°é€»è¾‘")
    print(f"ğŸ“Š åŒ…å«å®Œæ•´çš„5æ¬¡è°ƒç”¨tokenç»Ÿè®¡")
    print(f"ğŸ”¢ æµ‹è¯•æ ·æœ¬æ•°: {max_samples}")
    
    # åˆ›å»ºå®éªŒ
    experiment = MBPPTestExperiment(llm_config="openai/gpt-4o-mini")
    
    # è¿è¡Œæµ‹è¯•
    if max_samples == 1:
        # å•ä¸ªæµ‹è¯• - ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ·æœ¬
        data_files = [
            "data/datasets/mbpp_test.jsonl"
        ]
        
        sample = None
        for data_file in data_files:
            try:
                with open(data_file, 'r') as f:
                    sample = json.loads(f.readline().strip())
                break
            except FileNotFoundError:
                continue
        
        if sample:
            await experiment.test_single_problem(sample)
        else:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶!")
    else:
        # å¤šä¸ªæµ‹è¯•
        await experiment.test_multiple_problems(max_samples)

if __name__ == "__main__":
    asyncio.run(main()) 