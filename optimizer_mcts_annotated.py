"""
AFlowè’™ç‰¹å¡æ´›æ ‘æœç´¢ä¼˜åŒ–æµç¨‹è¯¦è§£

è¿™æ®µä»£ç å®ç°äº†AFlowè®ºæ–‡ä¸­çš„æ ¸å¿ƒä¼˜åŒ–ç®—æ³•ï¼Œç±»ä¼¼äºAlphaGoä¸­çš„MCTSï¼Œ
ä½†åº”ç”¨äºè‡ªåŠ¨åŒ–å·¥ä½œæµçš„ç”Ÿæˆå’Œä¼˜åŒ–ã€‚
"""

async def _optimize_graph(self):
    """
    ğŸš€ AFlowçš„æ ¸å¿ƒä¼˜åŒ–å¾ªç¯ï¼šè’™ç‰¹å¡æ´›æ ‘æœç´¢å·¥ä½œæµä¼˜åŒ–
    
    æ•´ä½“æµç¨‹ï¼š
    1. åˆå§‹åŒ–ï¼šåˆ›å»ºround_1çš„baseline
    2. è¿­ä»£ä¼˜åŒ–ï¼šä¸æ–­ç”Ÿæˆæ–°çš„å·¥ä½œæµå˜ä½“
    3. è¯„ä¼°éªŒè¯ï¼šæµ‹è¯•æ–°å·¥ä½œæµçš„æ€§èƒ½
    4. æ›´æ–°ç»éªŒï¼šå°†æˆåŠŸçš„ç­–ç•¥è®°å½•ä¸‹æ¥
    """
    validation_n = self.validation_rounds  # validation datasets's execution number
    graph_path = f"{self.root_path}/workflows"
    data = self.data_utils.load_results(graph_path)

    if self.round == 1:
        """
        ğŸ”„ ç¬¬ä¸€è½®ï¼šå»ºç«‹baseline
        - ä½¿ç”¨æœ€ç®€å•çš„å·¥ä½œæµï¼ˆé€šå¸¸æ˜¯ç©ºpromptï¼‰
        - è·å¾—åˆå§‹æ€§èƒ½åˆ†æ•°ä½œä¸ºåç»­ä¼˜åŒ–çš„å‚è€ƒç‚¹
        """
        #NOTE(sjh) å­˜roundçš„åœ°å€: round_1, round_2...
        directory = self.graph_utils.create_round_directory(graph_path, self.round) 

        # Load graph using graph_utils
        self.graph = self.graph_utils.load_graph(self.round, graph_path)
        # NOTE(sjh)è¿™é‡Œçš„self.graphæ˜¯Workflowç±»ï¼Œä¸æ˜¯Workflowå¯¹è±¡

        avg_score = await self.evaluation_utils.evaluate_graph(self, directory, validation_n, data, initial=True)

    # ğŸ”„ æ ¸å¿ƒä¼˜åŒ–å¾ªç¯ï¼šè’™ç‰¹å¡æ´›æ ‘æœç´¢
    while True:
        """
        ğŸ“Š MCTSçš„4ä¸ªæ ¸å¿ƒæ­¥éª¤ï¼šSelection â†’ Expansion â†’ Simulation â†’ Backpropagation
        
        åœ¨AFlowä¸­å¯¹åº”ï¼š
        - Selection: é€‰æ‹©çˆ¶èŠ‚ç‚¹è½®æ¬¡ï¼ˆé«˜åˆ†è½®æ¬¡æ›´å®¹æ˜“è¢«é€‰ä¸­ï¼‰
        - Expansion: åŸºäºçˆ¶èŠ‚ç‚¹ç”Ÿæˆæ–°çš„å·¥ä½œæµå˜ä½“
        - Simulation: è¯„ä¼°æ–°å·¥ä½œæµåœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½
        - Backpropagation: æ›´æ–°experienceï¼ŒæŒ‡å¯¼åç»­ä¼˜åŒ–
        """
        
        # ğŸ¯ æ­¥éª¤1ï¼šSelectionï¼ˆé€‰æ‹©é˜¶æ®µï¼‰
        # åˆ›å»ºæ–°è½®æ¬¡çš„ç›®å½•
        directory = self.graph_utils.create_round_directory(graph_path, self.round + 1)

        # ğŸ” è·å–å€™é€‰çˆ¶èŠ‚ç‚¹ï¼šå†å²ä¸Šè¡¨ç°æœ€å¥½çš„è½®æ¬¡
        top_rounds = self.data_utils.get_top_rounds(self.sample)
        """
        top_roundsç¤ºä¾‹ï¼š
        [
            {"round": 5, "score": 0.92},  # æœ€ä½³è½®æ¬¡
            {"round": 3, "score": 0.88},  # æ¬¡ä½³è½®æ¬¡  
            {"round": 1, "score": 0.80},  # baseline
            ...
        ]
        """
        
        # ğŸ² ä½¿ç”¨è½¯æ··åˆæ¦‚ç‡ç­–ç•¥é€‰æ‹©çˆ¶èŠ‚ç‚¹
        sample = self.data_utils.select_round(top_rounds)
        """
        è½¯æ··åˆæ¦‚ç‡ç­–ç•¥çš„æ ¸å¿ƒæ€æƒ³ï¼š
        - é«˜åˆ†è½®æ¬¡æœ‰æ›´é«˜æ¦‚ç‡è¢«é€‰ä¸­ï¼ˆåˆ©ç”¨exploitationï¼‰
        - æ‰€æœ‰è½®æ¬¡éƒ½æœ‰è¢«é€‰ä¸­çš„æœºä¼šï¼ˆæ¢ç´¢explorationï¼‰
        - é€šè¿‡Î»å‚æ•°æ§åˆ¶æ¢ç´¢vsåˆ©ç”¨çš„å¹³è¡¡
        
        ç»“æœï¼šsample = {"round": 5, "score": 0.92}
        """

        # ğŸ§¬ æ­¥éª¤2ï¼šExpansionï¼ˆæ‰©å±•é˜¶æ®µï¼‰
        # è¯»å–è¢«é€‰ä¸­çˆ¶èŠ‚ç‚¹çš„å·¥ä½œæµä»£ç å’Œprompt
        prompt, graph_load = self.graph_utils.read_graph_files(sample["round"], graph_path)
        graph = self.graph_utils.extract_solve_graph(graph_load)
        """
        è¯»å–çˆ¶èŠ‚ç‚¹çš„å…·ä½“å®ç°ï¼š
        - prompt: çˆ¶èŠ‚ç‚¹ä½¿ç”¨çš„æŒ‡ä»¤æ¨¡æ¿
        - graph_load: çˆ¶èŠ‚ç‚¹çš„å®Œæ•´å·¥ä½œæµä»£ç 
        - graph: æå–çš„æ ¸å¿ƒé€»è¾‘éƒ¨åˆ†
        """

        # ğŸ“š æ”¶é›†ä¼˜åŒ–æ‰€éœ€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        processed_experience = self.experience_utils.load_experience()
        experience = self.experience_utils.format_experience(processed_experience, sample["round"])
        """
        ExperienceåŒ…å«ï¼š
        - å†å²ä¸ŠæˆåŠŸ/å¤±è´¥çš„ä¿®æ”¹ç­–ç•¥
        - å“ªäº›æ“ä½œç¬¦ç»„åˆæ•ˆæœå¥½
        - é¿å…é‡å¤å·²çŸ¥çš„é”™è¯¯æ–¹å‘
        """
        
        operator_description = self.graph_utils.load_operators_description(self.operators)
        log_data = self.data_utils.load_log(sample["round"])
        """
        Additional Context:
        - operator_description: å¯ç”¨æ“ä½œç¬¦çš„è¯´æ˜æ–‡æ¡£
        - log_data: çˆ¶èŠ‚ç‚¹çš„å®é™…æ‰§è¡Œæ—¥å¿—ï¼ˆæˆåŠŸ/å¤±è´¥æ¡ˆä¾‹ï¼‰
        """

        # ğŸ¨ æ„é€ ä¼˜åŒ–promptï¼šæŒ‡å¯¼LLMç”Ÿæˆæ–°çš„å·¥ä½œæµ
        graph_optimize_prompt = self.graph_utils.create_graph_optimize_prompt(
            experience, sample["score"], graph[0], prompt, operator_description, self.type, log_data
        )
        """
        ä¼˜åŒ–promptåŒ…å«ï¼š
        - çˆ¶èŠ‚ç‚¹çš„å½“å‰å®ç°å’Œæ€§èƒ½
        - å†å²ç»éªŒæ•™è®­
        - å¯ç”¨çš„æ“ä½œç¬¦å·¥å…·ç®±
        - å…·ä½“çš„æ”¹è¿›ç›®æ ‡å’Œçº¦æŸ
        """

        # ğŸ¤– è°ƒç”¨ä¼˜åŒ–LLMç”Ÿæˆæ–°çš„å·¥ä½œæµ
        try:
            # Create XmlFormatter based on GraphOptimize model
            graph_formatter = XmlFormatter.from_model(GraphOptimize)
            
            # Call the LLM with formatter
            response = await self.optimize_llm.call_with_format(
                graph_optimize_prompt, 
                graph_formatter
            )
            """
            LLMè¾“å‡ºçš„æ–°å·¥ä½œæµåŒ…å«ï¼š
            - modification: å…·ä½“çš„ä¿®æ”¹æè¿°
            - new_graph: æ–°çš„å·¥ä½œæµä»£ç 
            - new_prompt: æ–°çš„æŒ‡ä»¤æ¨¡æ¿
            - reasoning: ä¿®æ”¹çš„ç†ç”±å’Œé¢„æœŸæ•ˆæœ
            """
            
            # If we reach here, response is properly formatted and validated
            logger.info(f"Graph optimization response received successfully")
        except FormatError as e:
            # Handle format validation errors
            logger.error(f"Format error in graph optimization: {str(e)}")
            # Try again with a fallback approach - direct call with post-processing
            raw_response = await self.optimize_llm(graph_optimize_prompt)
            
            # Try to extract fields using basic parsing
            response = self._extract_fields_from_response(raw_response)
            if not response:
                logger.error("Failed to extract fields from raw response, retrying...")
                continue

        # ğŸ” æ­¥éª¤3ï¼šSimulationï¼ˆæ¨¡æ‹Ÿè¯„ä¼°é˜¶æ®µï¼‰
        # æ£€æŸ¥æ–°ç”Ÿæˆçš„å·¥ä½œæµæ˜¯å¦ç¬¦åˆçº¦æŸæ¡ä»¶
        check = self.experience_utils.check_modification(
            processed_experience, response["modification"], sample["round"]
        )
        """
        æ£€æŸ¥åŒ…æ‹¬ï¼š
        - æ˜¯å¦é‡å¤äº†å·²çŸ¥å¤±è´¥çš„ä¿®æ”¹
        - æ˜¯å¦ç¬¦åˆåŸºæœ¬çš„è¯­æ³•å’Œé€»è¾‘è¦æ±‚
        - æ˜¯å¦åœ¨åˆç†çš„ä¿®æ”¹èŒƒå›´å†…
        
        check = True: æ–°å·¥ä½œæµé€šè¿‡åˆæ­¥éªŒè¯ï¼Œå¯ä»¥è¿›å…¥å®é™…æµ‹è¯•
        check = False: æ–°å·¥ä½œæµæœ‰é—®é¢˜ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ
        """

        # ğŸ¯ æ­¥éª¤4ï¼šBackpropagationï¼ˆåå‘ä¼ æ’­é˜¶æ®µï¼‰
        # If `check` is True, break the loop; otherwise, regenerate the graph
        if check:
            """
            âœ… æ–°å·¥ä½œæµé€šè¿‡éªŒè¯ï¼Œç»“æŸå½“å‰è½®æ¬¡çš„ç”Ÿæˆ
            
            æ¥ä¸‹æ¥ä¼šï¼š
            1. å°†æ–°å·¥ä½œæµä¿å­˜åˆ°round_N+1ç›®å½•
            2. åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å…¶æ€§èƒ½
            3. å°†ç»“æœå’Œç»éªŒæ›´æ–°åˆ°experienceæ•°æ®åº“
            4. ä¸ºä¸‹ä¸€è½®ä¼˜åŒ–åšå‡†å¤‡
            
            è¿™å½¢æˆäº†å®Œæ•´çš„MCTSå¾ªç¯ï¼š
            å¥½çš„ä¿®æ”¹ â†’ æ›´é«˜æ¦‚ç‡è¢«é€‰ä¸ºçˆ¶èŠ‚ç‚¹ â†’ äº§ç”Ÿæ›´å¤šå¥½çš„åä»£
            åçš„ä¿®æ”¹ â†’ è¾ƒä½æ¦‚ç‡è¢«é€‰ä¸­ â†’ é€æ¸è¢«æ·˜æ±°
            """
            break
        else:
            """
            âŒ æ–°å·¥ä½œæµéªŒè¯å¤±è´¥ï¼Œé‡æ–°å¼€å§‹MCTSå¾ªç¯
            
            ç³»ç»Ÿä¼šï¼š
            1. é‡æ–°é€‰æ‹©çˆ¶èŠ‚ç‚¹ï¼ˆå¯èƒ½é€‰ä¸­ä¸åŒçš„è½®æ¬¡ï¼‰
            2. ç”Ÿæˆæ–°çš„å·¥ä½œæµå˜ä½“
            3. ç›´åˆ°æ‰¾åˆ°åˆé€‚çš„å€™é€‰æ–¹æ¡ˆ
            
            è¿™ä½“ç°äº†MCTSçš„æ¢ç´¢æ€§ï¼šä¸ä¼šå›°åœ¨å±€éƒ¨æœ€ä¼˜è§£
            """
            logger.info("Generated workflow failed validation, retrying with different approach...")
            continue 