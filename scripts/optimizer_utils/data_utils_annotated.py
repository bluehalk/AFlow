import datetime
import json
import os
import random

import numpy as np
import pandas as pd

from scripts.logs import logger
from scripts.utils.common import read_json_file, write_json_file


class DataUtils:
    """
    AFlowçš„æ•°æ®ç®¡ç†ä¸­å¿ƒï¼Œå®ç°è’™ç‰¹å¡æ´›æ ‘æœç´¢çš„æ ¸å¿ƒç®—æ³•
    
    æ ¸å¿ƒèŒè´£ï¼š
    1. ç®¡ç†å®éªŒè½®æ¬¡æ•°æ®ï¼ˆåˆ†æ•°ã€æˆæœ¬ã€æ—¶é—´ï¼‰
    2. å®ç°è½¯æ··åˆæ¦‚ç‡ç­–ç•¥è¿›è¡Œçˆ¶èŠ‚ç‚¹é€‰æ‹©
    3. æä¾›å†å²ç»éªŒæ•°æ®æ”¯æŒ
    """
    
    def __init__(self, root_path: str):
        self.root_path = root_path
        self.top_scores = []  # å­˜å‚¨æ‰€æœ‰è½®æ¬¡çš„åˆ†æ•°æ•°æ®

    def load_results(self, path: str) -> list:
        """
        åŠ è½½å†å²å®éªŒç»“æœ
        
        Returns:
            list: åŒ…å«æ‰€æœ‰è½®æ¬¡ç»“æœçš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ ¼å¼ï¼š
                  {"round": 1, "score": 0.85, "avg_cost": 0.01, "total_cost": 0.10, "time": "..."}
        """
        result_path = os.path.join(path, "results.json")
        if os.path.exists(result_path):
            with open(result_path, "r") as json_file:
                try:
                    return json.load(json_file)
                except json.JSONDecodeError:
                    return []
        return []

    def get_top_rounds(self, sample: int, path=None, mode="Graph"):
        """
        ğŸ¯ è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼šè·å–å€™é€‰çˆ¶èŠ‚ç‚¹é›†åˆ
        
        ç­–ç•¥ï¼š
        1. å¿…é¡»åŒ…å«round_1ï¼ˆç¡®ä¿æœ‰baselineå¯¹æ¯”ï¼‰
        2. æŒ‰åˆ†æ•°é™åºæ’åˆ—ï¼Œå–å‰sampleä¸ªè½®æ¬¡
        3. å»é‡ç¡®ä¿æ¯ä¸ªè½®æ¬¡åªå‡ºç°ä¸€æ¬¡
        
        Args:
            sample: éœ€è¦è¿”å›çš„è½®æ¬¡æ•°é‡ï¼ˆå€™é€‰çˆ¶èŠ‚ç‚¹æ•°ï¼‰
            
        Returns:
            list: æ’åºåçš„å€™é€‰è½®æ¬¡åˆ—è¡¨ [{"round": 5, "score": 0.92}, ...]
        """
        # åŠ è½½æ‰€æœ‰è½®æ¬¡çš„åˆ†æ•°æ•°æ®
        self._load_scores(path, mode)
        unique_rounds = set()
        unique_top_scores = []

        # ğŸ”‘ ç­–ç•¥1ï¼šå¿…é¡»åŒ…å«ç¬¬ä¸€è½®ä½œä¸ºbaseline
        first_round = next((item for item in self.top_scores if item["round"] == 1), None)
        if first_round:
            unique_top_scores.append(first_round)
            unique_rounds.add(1)

        # ğŸ”‘ ç­–ç•¥2ï¼šæŒ‰åˆ†æ•°é™åºæ·»åŠ å…¶ä»–è½®æ¬¡
        for item in self.top_scores:
            if item["round"] not in unique_rounds:
                unique_top_scores.append(item)
                unique_rounds.add(item["round"])

                if len(unique_top_scores) >= sample:
                    break

        return unique_top_scores

    def select_round(self, items):
        """
        ğŸ² è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼šä½¿ç”¨è½¯æ··åˆæ¦‚ç‡ç­–ç•¥é€‰æ‹©çˆ¶èŠ‚ç‚¹
        
        è¿™æ˜¯AFlowè®ºæ–‡ä¸­çš„æ ¸å¿ƒç®—æ³•ï¼
        ç›®æ ‡ï¼šåœ¨æ¢ç´¢(exploration)å’Œåˆ©ç”¨(exploitation)ä¹‹é—´æ‰¾åˆ°å¹³è¡¡
        
        ç­–ç•¥ï¼š
        - é«˜åˆ†è½®æ¬¡æœ‰æ›´é«˜è¢«é€‰ä¸­æ¦‚ç‡ï¼ˆåˆ©ç”¨å·²çŸ¥å¥½ç»“æœï¼‰
        - æ‰€æœ‰è½®æ¬¡éƒ½æœ‰è¢«é€‰ä¸­çš„æœºä¼šï¼ˆæ¢ç´¢æ–°å¯èƒ½æ€§ï¼‰
        
        Args:
            items: å€™é€‰è½®æ¬¡åˆ—è¡¨ [{"round": 1, "score": 0.8}, {"round": 5, "score": 0.92}]
            
        Returns:
            dict: è¢«é€‰ä¸­çš„è½®æ¬¡ {"round": 5, "score": 0.92}
        """ 
        if not items:
            raise ValueError("Item list is empty.")

        # æŒ‰åˆ†æ•°é™åºæ’åˆ—ï¼ˆåˆ†æ•°è¶Šé«˜æ’åœ¨è¶Šå‰é¢ï¼‰
        sorted_items = sorted(items, key=lambda x: x["score"], reverse=True)
        scores = [item["score"] * 100 for item in sorted_items]  # æ”¾å¤§åˆ†æ•°ä¾¿äºè®¡ç®—

        # ğŸ¯ æ ¸å¿ƒï¼šè®¡ç®—è½¯æ··åˆæ¦‚ç‡åˆ†å¸ƒ
        probabilities = self._compute_probabilities(scores)
        logger.info(f"\nğŸ² Mixed probability distribution: {probabilities}")
        logger.info(f"\nğŸ“Š Sorted rounds: {sorted_items}")

        # ğŸ° æ ¹æ®æ¦‚ç‡åˆ†å¸ƒéšæœºé€‰æ‹©
        selected_index = np.random.choice(len(sorted_items), p=probabilities)
        logger.info(f"\nâœ… Selected index: {selected_index}, Selected item: {sorted_items[selected_index]}")

        return sorted_items[selected_index]

    def _compute_probabilities(self, scores, alpha=0.2, lambda_=0.3):
        """
        ğŸ§® è®¡ç®—è½¯æ··åˆæ¦‚ç‡åˆ†å¸ƒï¼ˆAFlowè®ºæ–‡æ ¸å¿ƒç®—æ³•ï¼‰
        
        å…¬å¼ï¼šP_mixed = Î» Ã— P_uniform + (1-Î») Ã— P_score
        
        å…¶ä¸­ï¼š
        - P_uniform: å‡åŒ€åˆ†å¸ƒï¼ˆæ¯ä¸ªè½®æ¬¡æ¦‚ç‡ç›¸ç­‰ï¼‰â†’ æ¢ç´¢æ€§
        - P_score: åŸºäºåˆ†æ•°çš„æŒ‡æ•°åˆ†å¸ƒï¼ˆé«˜åˆ†è½®æ¬¡æ¦‚ç‡æ›´é«˜ï¼‰â†’ åˆ©ç”¨æ€§
        - Î»: æ··åˆå‚æ•°ï¼Œæ§åˆ¶æ¢ç´¢vsåˆ©ç”¨çš„å¹³è¡¡
        - Î±: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶åˆ†æ•°æƒé‡çš„é”åº¦
        
        Args:
            scores: åˆ†æ•°æ•°ç»„ [80, 92, 85, ...]
            alpha: æ¸©åº¦å‚æ•°ï¼Œè¶Šå°åˆ†æ•°å·®å¼‚çš„å½±å“è¶Šå¤§
            lambda_: æ··åˆå‚æ•°ï¼Œè¶Šå¤§è¶Šå€¾å‘äºå‡åŒ€æ¢ç´¢
            
        Returns:
            numpy.array: æ¦‚ç‡åˆ†å¸ƒ [0.15, 0.45, 0.25, 0.15]
        """
        scores = np.array(scores, dtype=np.float64)
        n = len(scores)

        if n == 0:
            raise ValueError("Score list is empty.")

        # ğŸ“Š ç»„ä»¶1ï¼šå‡åŒ€æ¦‚ç‡åˆ†å¸ƒï¼ˆæ¢ç´¢æ€§ï¼‰
        # æ¯ä¸ªè½®æ¬¡éƒ½æœ‰ç›¸ç­‰çš„1/næ¦‚ç‡è¢«é€‰ä¸­
        uniform_prob = np.full(n, 1.0 / n, dtype=np.float64)

        # ğŸ“ˆ ç»„ä»¶2ï¼šåŸºäºåˆ†æ•°çš„æŒ‡æ•°åŠ æƒåˆ†å¸ƒï¼ˆåˆ©ç”¨æ€§ï¼‰
        max_score = np.max(scores)
        shifted_scores = scores - max_score  # æ•°å€¼ç¨³å®šæ€§ï¼šé¿å…expæº¢å‡º
        exp_weights = np.exp(alpha * shifted_scores)  # æŒ‡æ•°æƒé‡ï¼šexp(Î± Ã— score)

        sum_exp_weights = np.sum(exp_weights)
        if sum_exp_weights == 0:
            raise ValueError("Sum of exponential weights is 0, cannot normalize.")

        score_prob = exp_weights / sum_exp_weights  # å½’ä¸€åŒ–æ¦‚ç‡åˆ†å¸ƒ

        # ğŸ¯ æœ€ç»ˆï¼šè½¯æ··åˆæ¦‚ç‡åˆ†å¸ƒ
        # Î»æ§åˆ¶æ¢ç´¢vsåˆ©ç”¨çš„å¹³è¡¡ï¼š
        # - Î»=1: å®Œå…¨å‡åŒ€ï¼ˆçº¯æ¢ç´¢ï¼‰
        # - Î»=0: å®Œå…¨åŸºäºåˆ†æ•°ï¼ˆçº¯åˆ©ç”¨ï¼‰
        # - Î»=0.3: 30%æ¢ç´¢ + 70%åˆ©ç”¨
        mixed_prob = lambda_ * uniform_prob + (1 - lambda_) * score_prob

        # ç¡®ä¿æ¦‚ç‡å’Œä¸º1
        total_prob = np.sum(mixed_prob)
        if not np.isclose(total_prob, 1.0):
            mixed_prob = mixed_prob / total_prob

        return mixed_prob

    def load_log(self, cur_round, path=None, mode: str = "Graph"):
        """
        åŠ è½½æŒ‡å®šè½®æ¬¡çš„æ‰§è¡Œæ—¥å¿—
        
        ç”¨é€”ï¼š
        1. ä¸ºLLMæä¾›å†å²æ‰§è¡Œçš„å…·ä½“æ¡ˆä¾‹
        2. å¸®åŠ©ç†è§£å“ªäº›ç­–ç•¥æœ‰æ•ˆ/æ— æ•ˆ
        3. é¿å…é‡å¤ç›¸åŒçš„é”™è¯¯
        
        Args:
            cur_round: ç›®æ ‡è½®æ¬¡
            
        Returns:
            str: æ ¼å¼åŒ–çš„æ—¥å¿—æ–‡æœ¬ï¼ŒåŒ…å«éšæœºé€‰æ‹©çš„3ä¸ªæ‰§è¡Œæ ·ä¾‹
        """
        if mode == "Graph":
            log_dir = os.path.join(self.root_path, "workflows", f"round_{cur_round}", "log.json")
        else:
            log_dir = path

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(log_dir):
            return ""  # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        logger.info(log_dir)
        data = read_json_file(log_dir, encoding="utf-8")

        if isinstance(data, dict):
            data = [data]
        elif not isinstance(data, list):
            data = list(data)

        if not data:
            return ""

        # éšæœºé€‰æ‹©æœ€å¤š3ä¸ªæ ·ä¾‹ï¼Œé¿å…æ—¥å¿—è¿‡é•¿
        sample_size = min(3, len(data))
        random_samples = random.sample(data, sample_size)

        log = ""
        for sample in random_samples:
            log += json.dumps(sample, indent=4, ensure_ascii=False) + "\n\n"

        return log

    def get_results_file_path(self, graph_path: str) -> str:
        """è·å–ç»“æœæ–‡ä»¶è·¯å¾„"""
        return os.path.join(graph_path, "results.json")

    def create_result_data(self, round: int, score: float, avg_cost: float, total_cost: float) -> dict:
        """åˆ›å»ºè½®æ¬¡ç»“æœæ•°æ®ç»“æ„"""
        now = datetime.datetime.now()
        return {"round": round, "score": score, "avg_cost": avg_cost, "total_cost": total_cost, "time": now}

    def save_results(self, json_file_path: str, data: list):
        """ä¿å­˜å®éªŒç»“æœåˆ°JSONæ–‡ä»¶"""
        write_json_file(json_file_path, data, encoding="utf-8", indent=4)

    def _load_scores(self, path=None, mode="Graph"):
        """
        åŠ è½½æ‰€æœ‰è½®æ¬¡çš„å¹³å‡åˆ†æ•°æ•°æ®
        
        å¤„ç†ï¼š
        1. è¯»å–results.jsonæ–‡ä»¶
        2. æŒ‰è½®æ¬¡åˆ†ç»„è®¡ç®—å¹³å‡åˆ†æ•°
        3. æŒ‰åˆ†æ•°é™åºæ’åº
        
        Updates:
            self.top_scores: [{"round": 5, "score": 0.92}, {"round": 3, "score": 0.88}, ...]
        """
        if mode == "Graph":
            rounds_dir = os.path.join(self.root_path, "workflows")
        else:
            rounds_dir = path

        result_file = os.path.join(rounds_dir, "results.json")
        self.top_scores = []

        data = read_json_file(result_file, encoding="utf-8")
        df = pd.DataFrame(data)

        # æŒ‰è½®æ¬¡åˆ†ç»„ï¼Œè®¡ç®—æ¯è½®çš„å¹³å‡åˆ†æ•°
        scores_per_round = df.groupby("round")["score"].mean().to_dict()

        for round_number, average_score in scores_per_round.items():
            self.top_scores.append({"round": round_number, "score": average_score})

        # æŒ‰åˆ†æ•°é™åºæ’åºï¼ˆæœ€ä½³è½®æ¬¡åœ¨å‰ï¼‰
        self.top_scores.sort(key=lambda x: x["score"], reverse=True)

        return self.top_scores 