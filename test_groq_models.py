#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•Groq APIæ”¯æŒçš„æ¨¡å‹åç§°
"""

import asyncio
import sys
import os

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from scripts.async_llm import AsyncLLM, LLMConfig

# å¸¸è§çš„Groq Llamaæ¨¡å‹åç§°
GROQ_MODELS = [
    "llama3-70b-8192",
    # "llama-3.1-70b-versatile", 
    # "llama3-8b-8192",
    # "llama-3.1-8b-instant",
    # "llama-3.1-405b-reasoning"
]

async def test_model(model_name: str, api_key: str) -> bool:
    """æµ‹è¯•æŒ‡å®šæ¨¡å‹æ˜¯å¦å¯ç”¨"""
    try:
        config = LLMConfig({
            "model": model_name,
            "temperature": 0,
            "key": api_key,
            "base_url": "https://api.groq.com/openai/v1",
            "top_p": 1
        })
        
        llm = AsyncLLM(config)
        
        # å‘é€ç®€å•æµ‹è¯•è¯·æ±‚
        response = await llm("è®¡ç®— 2+2 ç­‰äºå¤šå°‘ï¼Ÿè¯·åªå›ç­”æ•°å­—ã€‚")
        
        print(f"âœ… {model_name}: å¯ç”¨ - å“åº”: {response.strip()}")
        return True
        
    except Exception as e:
        print(f"âŒ {model_name}: ä¸å¯ç”¨ - é”™è¯¯: {str(e)}")
        return False

async def find_working_model():
    """æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹"""
    # ä»é…ç½®æ–‡ä»¶è¯»å–API key
    try:
        import yaml
        with open("config/config2.yaml", 'r') as f:
            config_data = yaml.safe_load(f)
            api_key = config_data['models']['llama3-70b-8192']['api_key']
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–API key: {e}")
        return
    
    print("ğŸ” æµ‹è¯•Groq APIæ”¯æŒçš„æ¨¡å‹...")
    print("=" * 50)
    
    working_models = []
    
    for model in GROQ_MODELS:
        print(f"æµ‹è¯•æ¨¡å‹: {model}")
        is_working = await test_model(model, api_key)
        if is_working:
            working_models.append(model)
        print()
        
        # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
        await asyncio.sleep(1)
    
    print("=" * 50)
    if working_models:
        print("ğŸ‰ å¯ç”¨çš„æ¨¡å‹:")
        for model in working_models:
            print(f"  âœ… {model}")
        
        print(f"\nğŸ’¡ å»ºè®®ä¿®æ”¹ config/config2.yaml ä½¿ç”¨ä»¥ä¸‹æ¨¡å‹åç§°:")
        print(f"'{working_models[0]}'")
        
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹")
        print("è¯·æ£€æŸ¥:")
        print("1. API keyæ˜¯å¦æ­£ç¡®")
        print("2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("3. Groq APIæœåŠ¡æ˜¯å¦å¯ç”¨")

if __name__ == "__main__":
    asyncio.run(find_working_model()) 